{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN - Convolution Neural Networks"
      ],
      "metadata": {
        "id": "UStlbIXm0K31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma convolução é uma operação aplicada em uma imagem (ou em um mapa de características) que usa um filtro (ou kernel) para extrair características específicas. A operação convolucional aplica o filtro na imagem e gera um mapa de características, que é uma nova imagem mostrando as respostas do filtro em cada posição."
      ],
      "metadata": {
        "id": "tuh4K25U6tjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convoluções"
      ],
      "metadata": {
        "id": "X1wUbXei0FzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv 1x1\n"
      ],
      "metadata": {
        "id": "oK6KQkuE0oJ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição:\n",
        "* Uma convolução 1x1 usa um filtro (ou kernel) que tem dimensões 1x1.\n",
        "\n",
        "Propósito:\n",
        "* Apesar de parecer trivial, convoluções 1x1 são extremamente úteis. Elas permitem mudanças na profundidade dos mapas de características sem alterar suas dimensões espaciais (altura e largura).\n",
        "* Servem como uma forma eficiente de combinar informações de diferentes canais em um novo conjunto de canais, permitindo uma redução ou expansão dos canais.\n",
        "* Podem ser usadas para criar não-linearidades adicionais quando seguidas por uma função de ativação (como ReLU).\n",
        "\n",
        "Exemplo:\n",
        "* Se você tem um mapa de características com 64 canais e aplica uma convolução 1x1 com 32 filtros, o resultado será um novo mapa de características com 32 canais, mas com a mesma altura e largura que o original."
      ],
      "metadata": {
        "id": "3XAsnDj227Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Exemplificando uma imagem de 5x5 pixels:**\n",
        "```\n",
        "1 2 3 4 5\n",
        "6 7 8 9 1\n",
        "2 3 4 5 6\n",
        "7 8 9 1 2\n",
        "3 4 5 6 7\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "zmvYxS_l0sUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Um Kernel de 1x1**\n",
        "```\n",
        "0.5\n",
        "```"
      ],
      "metadata": {
        "id": "fmIhSWob2tCg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Multiplicando cada valor da imagem pelo kernel 1x1, obtem-se:**\n",
        "```\n",
        "0.5 1.0 1.5 2.0 2.5\n",
        "3.0 3.5 4.0 4.5 0.5\n",
        "1.0 1.5 2.0 2.5 3.0\n",
        "3.5 4.0 4.5 0.5 1.0\n",
        "1.5 2.0 2.5 3.0 3.5\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "um2LlGAi24ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv 3x3"
      ],
      "metadata": {
        "id": "CGuAPv433PEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição:\n",
        "* Uma convolução 3x3 usa um filtro de tamanho 3x3.\n",
        "\n",
        "Propósito:\n",
        "* Convoluções 3x3 são comuns porque conseguem capturar padrões espaciais locais, como bordas, cantos e texturas pequenas.\n",
        "* São um bom compromisso entre complexidade computacional e a capacidade de capturar informações espaciais.\n",
        "* Quando aplicadas em camadas profundas, ajudam a capturar relações entre características mais complexas.\n",
        "\n",
        "Exemplo:\n",
        "* Se você tem uma imagem ou um mapa de características, um filtro 3x3 é aplicado sobre ele movendo-se em passos (strides) definidos e computando a multiplicação e soma dos valores dos pixels dentro do filtro com os valores dos pesos do filtro."
      ],
      "metadata": {
        "id": "6FsyGsHJ3Wdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Exemplificando uma imagem de 5x5 pixels:**\n",
        "```\n",
        "1 2 3 4 5\n",
        "6 7 8 9 1\n",
        "2 3 4 5 6\n",
        "7 8 9 1 2\n",
        "3 4 5 6 7\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Z5N1ppIf4LeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Um Kernel de 3x3**\n",
        "```\n",
        "1 0 -1\n",
        "1 0 -1\n",
        "1 0 -1\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "N8AuJjLX4QTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Resultado da Convolução 3x3 (sem padding e stride de 1)**\n",
        "\n",
        "O kernel se aplica sobre a área 3x3 da imagem e a soma ponderada dos valores é calculada."
      ],
      "metadata": {
        "id": "hXpKPRsO4VWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Aplicando na primeira posição (topo-esquerda):\n",
        "1*1 + 2*0 + 3*(-1) +\n",
        "6*1 + 7*0 + 8*(-1) +\n",
        "2*1 + 3*0 + 4*(-1) = -7\n",
        "\n",
        "Resultado parcial:\n",
        "-7  ...  ...\n",
        "\n",
        "Deslocando o kernel para a direita:\n",
        "2*1 + 3*0 + 4*(-1) +\n",
        "7*1 + 8*0 + 9*(-1) +\n",
        "3*1 + 4*0 + 5*(-1) = -7\n",
        "\n",
        "Resultado parcial:\n",
        "-7 -7  ...\n",
        "\n",
        "Repetir esse processo para toda a imagem, obtendo:\n",
        "-7 -7 -4 -4\n",
        " 0  0  0  0\n",
        " 1  1  4  4\n",
        " 1  1  4  4\n",
        "```"
      ],
      "metadata": {
        "id": "nD-Qnp9I4e6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv 5x5"
      ],
      "metadata": {
        "id": "P_w0P67F5Yk6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definição:\n",
        "* Uma convolução 5x5 usa um filtro de tamanho 5x5.\n",
        "\n",
        "Propósito:\n",
        "* Convoluções 5x5 capturam padrões maiores e mais complexos do que convoluções 3x3, sendo capazes de considerar uma região maior da imagem ou mapa de características.\n",
        "* São úteis para capturar informações contextuais mais amplas, como padrões mais dispersos.\n",
        "\n",
        "Exemplo:\n",
        "* Similar à convolução 3x3, um filtro 5x5 percorre a imagem ou mapa de características e realiza multiplicação e soma dos valores dos pixels dentro do filtro com os valores dos pesos do filtro."
      ],
      "metadata": {
        "id": "o5AJQeNs5bVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Exemplificando uma imagem de 5x5 pixels:**\n",
        "```\n",
        "1 2 3 4 5\n",
        "6 7 8 9 1\n",
        "2 3 4 5 6\n",
        "7 8 9 1 2\n",
        "3 4 5 6 7\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "EkL9IACN5lNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Um kernel de 5x5:**\n",
        "```\n",
        " 0  1  2  1  0\n",
        " 1  2  3  2  1\n",
        " 2  3  4  3  2\n",
        " 1  2  3  2  1\n",
        " 0  1  2  1  0\n",
        "```"
      ],
      "metadata": {
        "id": "XhL4mjeM5q4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Resultado da Convolução 5x5 (sem padding e stride de 1)**\n",
        "\n",
        "Como a imagem e o kernel são do mesmo tamanho, aplicamos o kernel diretamente uma vez:\n",
        "\n",
        "```\n",
        " 1*0 + 2*1 + 3*2 + 4*1 + 5*0 +\n",
        " 6*1 + 7*2 + 8*3 + 9*2 + 1*1 +\n",
        " 2*2 + 3*3 + 4*4 + 5*3 + 6*2 +\n",
        " 7*1 + 8*2 + 9*3 + 1*2 + 2*1 +\n",
        " 3*0 + 4*1 + 5*2 + 6*1 + 7*0 = 160\n",
        "\n",
        "Resultado final:\n",
        "160\n",
        "```"
      ],
      "metadata": {
        "id": "rzySI-oO556m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling"
      ],
      "metadata": {
        "id": "I-VC98WC-xSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pooling é uma operação que reduz a dimensionalidade espacial de um mapa de características, mantendo a informação mais importante. Existem diferentes tipos de pooling, sendo os mais comuns:\n",
        "\n",
        "* Max Pooling: Seleciona o valor máximo de cada região (janela) da imagem.\n",
        "* Average Pooling: Calcula a média dos valores de cada região (janela) da imagem."
      ],
      "metadata": {
        "id": "asZlCI3e-z7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Projeção"
      ],
      "metadata": {
        "id": "k8_YaUge-6s4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Projeção, no contexto de CNNs e Inception, geralmente se refere a aplicar uma convolução 1x1 após a operação de pooling. A convolução 1x1 modifica a profundidade do mapa de características, ajustando o número de canais."
      ],
      "metadata": {
        "id": "q4orA5hd_A_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling com Projeção"
      ],
      "metadata": {
        "id": "pJ49mnCt_O0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No módulo de Inception, pooling com projeção é uma combinação de uma operação de pooling seguida por uma convolução 1x1. Essa combinação é usada para:\n",
        "\n",
        "1. Reduzir a Dimensionalidade Espacial: A operação de pooling reduz a altura e a largura do mapa de características, diminuindo a quantidade de informações espaciais, mas mantendo a informação mais relevante.\n",
        "2. Manter a Profundidade Controlada: A convolução 1x1 após o pooling ajusta a profundidade do mapa de características, permitindo a combinação eficiente de diferentes tipos de informações extraídas pelas outras convoluções (1x1, 3x3 e 5x5) no módulo de Inception."
      ],
      "metadata": {
        "id": "lj1qxVQ3_SZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exemplo Prático\n",
        "\n",
        "Vamos considerar um exemplo prático usando pooling com projeção em um módulo de Inception.\n",
        "\n",
        "Entrada\n",
        "* Mapa de características de entrada: Suponha que temos um mapa de características de tamanho 8x8x64 (altura x largura x canais).\n",
        "\n",
        "Pooling\n",
        "* Max Pooling: Usamos uma janela 3x3 com stride 1 e padding 'same'.\n",
        "O resultado é um mapa de características de tamanho 8x8x64, pois o padding 'same' mantém as dimensões espaciais.\n",
        "\n",
        "Projeção\n",
        "* Convolução 1x1: Aplicamos uma convolução 1x1 com, digamos, 32 filtros.\n",
        "Isso ajusta a profundidade do mapa de características para 32, resultando em um mapa de características de tamanho 8x8x32.\n",
        "\n",
        "Combinação no Módulo de Inception\n",
        "* No módulo de Inception, essa operação de pooling com projeção é combinada com as outras convoluções (1x1, 3x3, 5x5) e suas respectivas projeções."
      ],
      "metadata": {
        "id": "Xo-s_UtQKcgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OBS"
      ],
      "metadata": {
        "id": "vYHNfaOKmXeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Lembre-se que os canais de cores são combinados (somados) ao final da primeira camada de convulção, logo, uma imagem 5x5x3 ao passar por um filtro 3x3x3, se torna um combinação 2D de apenas 3x3.\n",
        "\n",
        ">A mesma lógica é mantida para novas camadas de convulção, caso o resultado de um pooling seja 8 mapas de ativação 3x3, a nova camada de convulção realizara o produto escalar e em seguida irá combinar o valor de mapas, repetindo este processo pelo novo número de features informado.\n",
        "\n",
        ">Este processo de chama **soma em profundiade**, esta combinação de mapas de ativação é o que torna o modelo capaz de progressivamente entender caracteristicas mais completas de imagens, por exemplo:\n",
        "\n",
        "```\n",
        "[Imagem RGB 32x32x3]\n",
        "        │\n",
        "   Conv2D 32 filtros 3x3\n",
        "        │\n",
        "  [32 mapas 32x32] ← bordas, cores, cantos\n",
        "        │\n",
        "   MaxPooling 2x2\n",
        "        │\n",
        "  [32 mapas 16x16] ← padrões mais fortes\n",
        "        │\n",
        "   Conv2D 64 filtros 3x3\n",
        "        │\n",
        "  [64 mapas 14x14] ← mapas de ativaçao|padrões combinados (olhos, orelha e etc)\n",
        "        │\n",
        "   MaxPooling 2x2\n",
        "        │\n",
        "  [64 mapas 7x7] ← padrões hierárquicos fortes\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "y67bGRlemZM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação da CNN GoogLeNet Inception v1\n",
        "\n",
        "Utilizaremos um exemplo desenvolvido pelo Google Brain para visão computacional, denominado Inception."
      ],
      "metadata": {
        "id": "xFplU0uu632p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bibliotecas a serem utilizadas"
      ],
      "metadata": {
        "id": "1cN0an6q7H_U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas necessárias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifica a quantidade de GPUs disponíveis\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eur64eakk6sL",
        "outputId": "31689841-159d-4e57-abfa-22df4f11fd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database"
      ],
      "metadata": {
        "id": "vx4493jy7ONl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Função load_cifar10_data:` Essa função é responsável por carregar os dados do dataset CIFAR-10 e realizar o pré-processamento necessário, como redimensionar as imagens, transformar os rótulos para um formato categórico e normalizar os valores dos pixels das imagens.\n",
        "\n",
        "`Parâmetros 32, 32:` Esses parâmetros são usados para especificar as dimensões das imagens após o redimensionamento. No caso, 32 e 32 representam a largura e a altura das imagens, respectivamente. Ou seja, cada imagem do CIFAR-10 será redimensionada para 32x32 pixels."
      ],
      "metadata": {
        "id": "yj4Y8UHuw3f1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para carregar e processar os dados do CIFAR-10\n",
        "def load_cifar10_data(img_rows, img_cols):\n",
        "    # Carrega os dados de treino e validação do CIFAR-10\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Redimensiona as imagens de treino e validação\n",
        "    X_train = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_train])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows, img_cols)) for img in X_valid])\n",
        "\n",
        "    # Converte os rótulos para o formato categórico\n",
        "    num_classes = 10\n",
        "    Y_train = to_categorical(Y_train, num_classes)\n",
        "    Y_valid = to_categorical(Y_valid, num_classes)\n",
        "\n",
        "    # Converte as imagens para o tipo 'float32' e normaliza os dados\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    X_valid = X_valid.astype('float32') / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid"
      ],
      "metadata": {
        "id": "nhP-dbVLUL66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega e pré-processa os dados do CIFAR-10, alterando o tamanho da imagem para 32x32 pixels\n",
        "X_train, y_train, X_test, y_test = load_cifar10_data(32, 32)"
      ],
      "metadata": {
        "id": "Sx11LzhRUO4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c084aeca-f15d-4c3a-a342-369d3730730c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`kernel_init:` Este inicializador é usado para definir os valores iniciais dos pesos das camadas convolucionais usando o método Glorot Uniform. Ele ajuda a garantir que as ativações não sejam nem muito grandes nem muito pequenas, facilitando o treinamento eficiente da rede.\n",
        "\n",
        "*   `tf.keras.initializers.GlorotUniform()`\n",
        "    * Este é um inicializador de pesos que também é conhecido como Xavier Uniform Initializer.\n",
        "    * Ele é projetado para manter a variação das ativações através das camadas da rede constante.\n",
        "    * Funciona inicializando os pesos com valores aleatórios retirados de uma distribuição uniforme dentro de um intervalo específico, que depende do número de unidades nas camadas de entrada e saída.\n",
        "    * Este método é amplamente utilizado porque ajuda a acelerar a convergência do modelo.\n",
        "*   `tf.keras.initializers.Constant(value=0.2)`\n",
        "    * Este é um inicializador de bias que define todos os valores de bias para um valor constante, neste caso, 0.2.\n",
        "    * Inicializar os bias com um valor constante pode ser útil, especialmente para evitar iniciar com todos os bias iguais a zero, o que pode causar certas simetrias que são indesejáveis no treinamento inicial da rede.\n",
        "\n",
        "\n",
        "`bias_init:` Este inicializador define os valores iniciais dos bias das camadas convolucionais como 0.2, fornecendo um valor constante diferente de zero para os bias, o que pode ajudar a quebrar a simetria e permitir que a rede aprenda de forma mais eficiente desde o início."
      ],
      "metadata": {
        "id": "3sNlDJ4vxHLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializadores de kernel (pesos iniciais) e bias\n",
        "kernel_init = tf.keras.initializers.GlorotUniform()\n",
        "bias_init = tf.keras.initializers.Constant(value=0.2)"
      ],
      "metadata": {
        "id": "L2PkbsZSbilv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception Module"
      ],
      "metadata": {
        "id": "q0bXYY42zKGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função inception_module recebe como entrada:\n",
        "\n",
        "* `x`: o tensor de entrada (normalmente uma camada anterior).\n",
        "* `filters_1x1`: o número de filtros para a convolução 1x1.\n",
        "* `filters_3x3_reduce`: o número de filtros para a camada de redução antes da convolução 3x3.\n",
        "* `filters_3x3`: o número de filtros para a convolução 3x3.\n",
        "* `filters_5x5_reduce`: o número de filtros para a camada de redução antes da convolução 5x5.\n",
        "* `filters_5x5`: o número de filtros para a convolução 5x5.\n",
        "* `filters_pool_proj`: o número de filtros para a projeção após a camada de pooling.\n",
        "name: opcional, o nome do módulo de Inception."
      ],
      "metadata": {
        "id": "dp4mBRo87W4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolução 1x1\n",
        "\n",
        "* `Conv2D`: Cria uma camada de convolução bidimensional.\n",
        "* `filters_1x1`: Número de filtros usados na convolução 1x1.\n",
        "* `(1, 1)`: Tamanho do kernel (filtro) é 1x1.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada, adicionando zeros nas bordas quando necessário.\n",
        "* `activation='relu'`: Função de ativação ReLU (Rectified Linear Unit). M ais funções de ativação na [documentação do tensorflow](https://www.tensorflow.org/api_docs/python/tf/keras/activations)\n",
        "* `kernel_initializer`: Inicializador para os pesos da camada, aqui usando kernel_init.\n",
        "* `bias_initializer`: Inicializador para os biases da camada, aqui usando bias_init.\n",
        "`(x)`: A camada recebe o tensor de entrada x"
      ],
      "metadata": {
        "id": "4a5Tllju76gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolução 3x3 com redução\n",
        "\n",
        "* `conv_3x3_reduce`: Primeira camada é uma convolução 1x1 para reduzir a dimensionalidade.\n",
        "* `filters_3x3_reduce`: Número de filtros para a camada de redução.\n",
        "* `(1, 1)`: Tamanho do kernel é 1x1.\n",
        "* `conv_3x3`: Segunda camada é uma convolução 3x3 aplicada na saída da camada anterior.\n",
        "* `filters_3x3`: Número de filtros para a convolução 3x3.\n",
        "* `(3, 3)`: Tamanho do kernel é 3x3."
      ],
      "metadata": {
        "id": "NzD-cl4f9ipG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolução 5x5 com redução\n",
        "\n",
        "* `conv_5x5_reduce`: Primeira camada é uma convolução 1x1 para reduzir a dimensionalidade.\n",
        "* `filters_5x5_reduce`: Número de filtros para a camada de redução.\n",
        "* `(1, 1)`: Tamanho do kernel é 1x1.\n",
        "* `conv_5x5`: Segunda camada é uma convolução 5x5 aplicada na saída da camada anterior.\n",
        "* `filters_5x5`: Número de filtros para a convolução 5x5.\n",
        "* `(5, 5)`: Tamanho do kernel é 5x5."
      ],
      "metadata": {
        "id": "CZlB5__T94iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pooling com projeção\n",
        "\n",
        "```\n",
        "pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "```\n",
        "\n",
        "* `MaxPooling2D`: Cria uma camada de max pooling.\n",
        "* `(3, 3)`: Tamanho da janela de pooling (3x3 pixels).\n",
        "* `strides=(1, 1)`: Passo da janela de pooling (move-se 1 pixel de cada vez).\n",
        "* `padding='same'`: Mantém as dimensões espaciais da entrada, adicionando zeros quando necessário.\n",
        "* `(x)`: Aplica a operação ao tensor de entrada x.\n",
        "\n",
        "```\n",
        "pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "```\n",
        "\n",
        "* `Conv2D`: Cria uma camada de convolução.\n",
        "* `filters_pool_proj`: Número de filtros para a convolução 1x1 (determina a profundidade do mapa de características de saída).\n",
        "* `(1, 1)`: Tamanho do kernel (filtro) é 1x1.\n",
        "* `padding='same'`: Mantém as dimensões espaciais da entrada.\n",
        "* `activation='relu'`: Função de ativação ReLU (Rectified Linear Unit).\n",
        "* `kernel_initializer` e `bias_initializer`: Inicializadores dos pesos e biases.\n",
        "* `(pool_proj)`: Aplica a convolução ao mapa de características resultante da operação de pooling.\n"
      ],
      "metadata": {
        "id": "5wTLTV0m-UEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para criar um módulo de Inception\n",
        "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None):\n",
        "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "\n",
        "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)\n",
        "\n",
        "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)\n",
        "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)\n",
        "\n",
        "    pool_proj = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(pool_proj)\n",
        "\n",
        "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
        "    return output"
      ],
      "metadata": {
        "id": "D--rGnrZUcmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do Modelo de Inception"
      ],
      "metadata": {
        "id": "RSVm7XCMLmo-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumo do Fluxo de Camadas**\n",
        "\n",
        "1. Camada de Entrada: Recebe imagens de 32x32 pixels com 3 canais (RGB).\n",
        "2. Convolução 7x7: Aplica 64 filtros 7x7 com stride 2, reduzindo a dimensão espacial e extraindo características iniciais.\n",
        "3. Max Pooling 3x3: Reduz ainda mais a dimensão espacial com janela 3x3 e stride 2.\n",
        "4. Convolução 1x1: Modifica a profundidade para 64, mantendo a dimensão espacial.\n",
        "5. Convolução 3x3: Aplica 192 filtros 3x3 para extrair características mais complexas.\n",
        "6. Max Pooling 3x3: Reduz novamente a dimensão espacial com janela 3x3 e stride 2."
      ],
      "metadata": {
        "id": "mmetNaDUO67E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = Input(shape=(32, 32, 3))"
      ],
      "metadata": {
        "id": "7PzyUY7lXn_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Input`: Cria uma camada de entrada que especifica a forma da entrada.\n",
        "* `shape=(32, 32, 3)`: As entradas são imagens de 32x32 pixels com 3 canais (RGB)."
      ],
      "metadata": {
        "id": "feGf_WiWLpcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7div2', kernel_initializer=kernel_init, bias_initializer=bias_init)(input_layer)"
      ],
      "metadata": {
        "id": "xd0uLHBvMlPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Conv2D`: Cria uma camada de convolução bidimensional.\n",
        "64: Número de filtros na convolução.\n",
        "* `(7, 7)`: Tamanho do kernel (filtro) é 7x7.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada, com preenchimento de zeros nas bordas quando necessário.\n",
        "* `strides=(2, 2)`: O kernel se move 2 pixels de cada vez na horizontal e na vertical, reduzindo as dimensões espaciais da saída.\n",
        "* `activation='relu'`: Função de ativação ReLU (Rectified Linear Unit).\n",
        "* `name='conv_1_7x7div2'`: Nome da camada.\n",
        "* `kernel_initializer=kernel_init`: Inicializador para os pesos da camada.\n",
        "* `bias_initializer=bias_init`: Inicializador para os bias da camada.\n",
        "* `(input_layer)`: Aplica a convolução ao tensor de entrada input_layer"
      ],
      "metadata": {
        "id": "oIFCjQ_oMBLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3div2')(x)"
      ],
      "metadata": {
        "id": "WsFEk4vsM_qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `MaxPooling2D`: Cria uma camada de pooling máximo bidimensional.\n",
        "* `(3, 3)`: Tamanho da janela de pooling é 3x3.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada, com preenchimento de zeros nas bordas quando necessário.\n",
        "* `strides=(2, 2)`: A janela de pooling se move 2 pixels de cada vez, reduzindo as dimensões espaciais da saída.\n",
        "* `name='max_pool_1_3x3div2'`: Nome da camada.\n",
        "* `(x)`: Aplica a operação de pooling ao tensor `x` resultante da camada anterior."
      ],
      "metadata": {
        "id": "CPxlYP07Me76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv2D(64, (1, 1), padding='same', activation='relu', name='conv_2a_3x3div1')(x)"
      ],
      "metadata": {
        "id": "6WvQ34xiMCrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Conv2D`: Cria outra camada de convolução bidimensional.\n",
        "* `64`: Número de filtros na convolução.\n",
        "* `(1, 1)`: Tamanho do kernel é 1x1, usado para modificar a profundidade do tensor sem alterar as dimensões espaciais.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada.\n",
        "* `activation='relu'`: Função de ativação ReLU.\n",
        "* `name='conv_2a_3x3div1'`: Nome da camada.\n",
        "* `kernel_initializer=kernel_init`: Inicializador para os pesos da camada.\n",
        "* `bias_initializer=bias_init`: Inicializador para os bias da camada.\n",
        "* `(x)`: Aplica a convolução ao tensor `x` resultante da camada anterior."
      ],
      "metadata": {
        "id": "1XW3XmccM-1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Conv2D(192, (3, 3), padding='same', activation='relu', name='conv_2b_3x3div1')(x)"
      ],
      "metadata": {
        "id": "NLl9cZcgNo58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Conv2D`: Cria outra camada de convolução bidimensional.\n",
        "* `192`: Número de filtros na convolução.\n",
        "* `(1, 1)`: Tamanho do kernel é 1x1, usado para modificar a profundidade do tensor sem alterar as dimensões espaciais.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada.\n",
        "* `activation='relu'`: Função de ativação ReLU.\n",
        "* `name='conv_2b_3x3div1'`: Nome da camada.\n",
        "* `kernel_initializer=kernel_init`: Inicializador para os pesos da camada.\n",
        "* `bias_initializer=bias_init`: Inicializador para os bias da camada.\n",
        "* `(x)`: Aplica a convolução ao tensor `x` resultante da camada anterior."
      ],
      "metadata": {
        "id": "dS5RmiEDMjaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3div2')(x)"
      ],
      "metadata": {
        "id": "Dg2RPaJ0NrDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `MaxPooling2D`: Cria uma camada de pooling máximo bidimensional.\n",
        "* `(3, 3)`: Tamanho da janela de pooling é 3x3.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada, com preenchimento de zeros nas bordas quando necessário.\n",
        "* `strides=(2, 2)`: A janela de pooling se move 2 pixels de cada vez, reduzindo as dimensões espaciais da saída.\n",
        "* `name='max_pool_2_3x3div2'`: Nome da camada.\n",
        "* `(x)`: Aplica a operação de pooling ao tensor `x` resultante da camada anterior."
      ],
      "metadata": {
        "id": "7ahvTJLENqkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adição de módulos de Inception (x)"
      ],
      "metadata": {
        "id": "8zzLXACrPPxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após o processamento do modelo de Inception, a saída resultante torna-se entrada a ser passada por módulos de Inception, que combinarão várias operações de convolução e pooling em paralelo para extrair características em diferentes escalas."
      ],
      "metadata": {
        "id": "DxhulYnqOkta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumo do Processo**\n",
        "\n",
        "1. Primeiro Módulo de Inception:\n",
        "\n",
        "    * Aplica várias convoluções (1x1, 3x3 com redução, 5x5 com redução) e pooling seguido de uma projeção (convolução 1x1).\n",
        "    * Combina as saídas dessas operações em um único tensor.\n",
        "\n",
        "2. Segundo Módulo de Inception:\n",
        "\n",
        "    * Aplica um conjunto diferente de convoluções e pooling, mas com a mesma estrutura.\n",
        "    * Combina as saídas dessas operações em um único tensor.\n",
        "\n",
        "3. Pooling Máximo:\n",
        "\n",
        "    * Reduz as dimensões espaciais do tensor de saída resultante dos módulos de Inception.\n",
        "    * Mantém a profundidade do tensor, mas reduz a resolução espacial, o que ajuda a capturar características mais abstratas e reduzir a complexidade computacional para as camadas subsequentes.\n",
        "\n",
        "Esses passos são parte da construção do modelo de Inception, onde diferentes escalas de convoluções e pooling são usadas para extrair características complexas e variadas da entrada, seguidos por operações de pooling para compactar e resumir a informação."
      ],
      "metadata": {
        "id": "MO4fs2_1X4Aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primeiro módulo Inception"
      ],
      "metadata": {
        "id": "QKogYsB6eNCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = inception_module(x, filters_1x1=64, filters_3x3_reduce=96, filters_3x3=128, filters_5x5_reduce=16, filters_5x5=32, filters_pool_proj=32, name='inception_3a')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOemeHUhPXqN",
        "outputId": "3119a7f7-b100-4467-c443-94724694a2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro módulo de Inception é adicionado ao modelo:\n",
        "\n",
        "1. `inception_module`: Chama a função inception_module para criar e aplicar um módulo de Inception à entrada `x`.\n",
        "2. `filters_1x1=64`: Define 64 filtros para a convolução 1x1.\n",
        "3. `filters_3x3_reduce=96`: Define 96 filtros para a camada de redução antes da convolução 3x3.\n",
        "4. `filters_3x3=128`: Define 128 filtros para a convolução 3x3.\n",
        "5. `filters_5x5_reduce=16`: Define 16 filtros para a camada de redução antes da convolução 5x5.\n",
        "6. `filters_5x5=32`: Define 32 filtros para a convolução 5x5.\n",
        "7. `filters_pool_proj=32`: Define 32 filtros para a projeção após a camada de pooling.\n",
        "8. `name='inception_3a'`: Define o nome do módulo como `inception_3a`.\n",
        "\n",
        "\n",
        "Esses parâmetros configuram o módulo de Inception para combinar múltiplas convoluções (1x1, 3x3, 5x5) e pooling em paralelo, concatenando suas saídas."
      ],
      "metadata": {
        "id": "TDpSAwkjYOrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Segundo módulo Inception"
      ],
      "metadata": {
        "id": "AgN4wDpJeRwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = inception_module(x, filters_1x1=128, filters_3x3_reduce=128, filters_3x3=192, filters_5x5_reduce=32, filters_5x5=96, filters_pool_proj=64, name='inception_3b')"
      ],
      "metadata": {
        "id": "8OsSq5ZRYPCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segundo módulo de Inception com diferentes configurações de filtros:\n",
        "\n",
        "1. `filters_1x1=128`: Define 128 filtros para a convolução 1x1.\n",
        "2. `filters_3x3_reduce=128`: Define 128 filtros para a camada de redução antes da convolução 3x3.\n",
        "3. `filters_3x3=192`: Define 192 filtros para a convolução 3x3.\n",
        "4. `filters_5x5_reduce=32`: Define 32 filtros para a camada de redução antes da convolução 5x5.\n",
        "5. `filters_5x5=96`: Define 96 filtros para a convolução 5x5.\n",
        "6. `filters_pool_proj=64`: Define 64 filtros para a projeção após a camada de pooling.\n",
        "7. `name='inception_3b'`: Define o nome do módulo como `inception_3b`.\n",
        "\n",
        "Este módulo de Inception, assim como o primeiro, combina várias convoluções e pooling para extrair características em diferentes escalas."
      ],
      "metadata": {
        "id": "7bgJphhVYo9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MaxPooling dos dois primeiros módulos"
      ],
      "metadata": {
        "id": "-S7c9eXbeWtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = MaxPooling2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3div2')(x)"
      ],
      "metadata": {
        "id": "9KhcrcLbYpPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após os módulos de Inception, uma camada de pooling máximo é aplicada:\n",
        "\n",
        "1. `MaxPooling2D`: Cria uma camada de pooling máximo bidimensional.\n",
        "2. `(3, 3)`: Tamanho da janela de pooling é 3x3.\n",
        "3. `padding='same'`: Mantém as dimensões espaciais da saída iguais às da entrada, adicionando zeros nas bordas quando necessário.\n",
        "4. `strides=(2, 2)`: A janela de pooling se move 2 pixels de cada vez na horizontal e na vertical, reduzindo as dimensões espaciais da saída.\n",
        "5. `name='max_pool_3_3x3div2'`: Nome da camada é `max_pool_3_3x3div2`.\n",
        "6. `(x)`: Aplica a operação de pooling ao tensor `x` resultante dos módulos de Inception anteriores."
      ],
      "metadata": {
        "id": "FNmG0CsFZGbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classificadores auxiliares (x1)"
      ],
      "metadata": {
        "id": "fEIHqYWpPh4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este trecho de código implementa um classificador auxiliar, que é uma saída adicional na rede Inception. Esse classificador auxiliar ajuda no treinamento, fornecendo gradientes adicionais para camadas intermediárias, o que pode facilitar a convergência e mitigar o problema de gradientes desvanecentes."
      ],
      "metadata": {
        "id": "pci8L0A1Z1qT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Propósito do Classificador Auxiliar**\n",
        "\n",
        "O classificador auxiliar ajuda a rede a aprender melhor ao adicionar uma perda auxiliar durante o treinamento. Isso proporciona gradientes adicionais às camadas intermediárias, ajudando a evitar o problema de gradientes desvanecentes e acelerando a convergência da rede profunda. Durante a inferência, essa saída auxiliar pode ser ignorada, e apenas a saída principal da rede é usada para fazer previsões."
      ],
      "metadata": {
        "id": "fWZsRW_8cfm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumo do Processo**\n",
        "\n",
        "1. `AveragePooling2D`: Reduz a resolução espacial pela metade com uma janela de 3x3 e stride de 2.\n",
        "2. `Conv2D 1x1`: Ajusta a profundidade do tensor para 128 canais.\n",
        "3. `Flatten`: Achata o tensor 4D (altura, largura, canais) em um vetor 1D.\n",
        "4. `Dense 1024`: Aplica uma camada totalmente conectada com 1024 neurônios e ativação ReLU.\n",
        "5. `Dropout`: Aplica dropout com uma taxa de 70% para evitar overfitting.\n",
        "6. `Dense 10`: Aplica a camada de saída com 10 neurônios e ativação softmax, produzindo a distribuição de probabilidade sobre as 10 classes do CIFAR-10."
      ],
      "metadata": {
        "id": "3nR0i6_8cM6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = AveragePooling2D((3, 3), strides=2, padding='same')(x)"
      ],
      "metadata": {
        "id": "--WbSqxzPoVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `AveragePooling2D`: Aplica uma camada de pooling médio bidimensional.\n",
        "* `(3, 3)`: Tamanho da janela de pooling é 3x3.\n",
        "* `strides=2`: A janela de pooling se move 2 pixels de cada vez, reduzindo a resolução espacial pela metade.\n",
        "* `padding='same'`: A saída tem o mesmo tamanho que a entrada, com preenchimento de zeros nas bordas quando necessário.\n",
        "* `(x)`: Aplica a operação de pooling ao tensor x resultante das camadas anteriores."
      ],
      "metadata": {
        "id": "U5p1ecJsaA_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)"
      ],
      "metadata": {
        "id": "fOxfVVveaBSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Conv2D`: Aplica uma camada de convolução bidimensional.\n",
        "* `128`: Número de filtros na convolução.\n",
        "* `(1, 1)`: Tamanho do kernel é 1x1, usado para modificar a profundidade do tensor sem alterar as dimensões espaciais.\n",
        "* `padding='same'`: Mantém as dimensões espaciais da entrada.\n",
        "* `activation='relu'`: Função de ativação ReLU.\n",
        "* `(x1)`: Aplica a convolução ao tensor `x1` resultante da camada de pooling médio."
      ],
      "metadata": {
        "id": "HQY-pXM6agrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Flatten()(x1)"
      ],
      "metadata": {
        "id": "qtN2lRZ4ahBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Flatten`: Achata o tensor de entrada em uma única dimensão (vetor), preparando-o para ser passado para uma camada totalmente conectada (densa)."
      ],
      "metadata": {
        "id": "uZxuJIZ9bYxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Dense(2048, activation='relu')(x1)"
      ],
      "metadata": {
        "id": "F-nq6Hq-bZEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Dense`: Aplica uma camada totalmente conectada (densa).\n",
        "* `1024`: Número de neurônios na camada densa.\n",
        "* `activation='relu'`: Função de ativação ReLU.\n",
        "* `(x1)`: Aplica a camada densa ao tensor achatado."
      ],
      "metadata": {
        "id": "KTECxDOBbg9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Dropout(0.2)(x1)"
      ],
      "metadata": {
        "id": "Vct4EW2mbhWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Dropout`: Aplica uma camada de dropout, que desativa aleatoriamente 70% dos neurônios durante o treinamento para evitar overfitting.\n",
        "* `0.7`: Taxa de dropout (70% dos neurônios são desativados aleatoriamente).\n",
        "* `(x1)`: Aplica a camada de dropout ao tensor resultante da camada densa."
      ],
      "metadata": {
        "id": "F02VTtXDbuPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = Dense(10, activation='softmax', name='auxilliary_output_1')(x1)"
      ],
      "metadata": {
        "id": "7pj9GaiwbugX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Dense`: Aplica outra camada totalmente conectada (densa).\n",
        "* `10`: Número de neurônios na camada de saída, correspondente ao número de classes no CIFAR-10.\n",
        "* `activation='softmax'`: Função de ativação softmax, que converte os valores dos neurônios em probabilidades.\n",
        "* `name='auxilliary_output_1'`: Nome da camada de saída auxiliar.\n",
        "* `(x1)`: Aplica a camada densa ao tensor resultante da camada de dropout"
      ],
      "metadata": {
        "id": "kuGhxjLKb8UR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mais módulos de Inception e o classificador final"
      ],
      "metadata": {
        "id": "WmNSc7wGPo_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este trecho de código define a parte final da rede Inception, onde as características extraídas são compactadas e transformadas em previsões de classe através de uma camada totalmente conectada com softmax."
      ],
      "metadata": {
        "id": "yiNDRBS4d_3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resumo do Processo**\n",
        "\n",
        "1. Módulos de Inception (5a e 5b):\n",
        "\n",
        "    * Cada módulo de Inception combina várias convoluções (1x1, 3x3 com redução, 5x5 com redução) e pooling seguido de uma projeção (convolução 1x1).\n",
        "    * As saídas dessas operações são concatenadas para formar um único tensor de saída.\n",
        "\n",
        "2. Global Average Pooling:\n",
        "\n",
        "    * Reduz cada mapa de características a um único valor (a média), resultando em um vetor de saída com uma dimensão por canal.\n",
        "    * Prepara os dados para a camada densa final, reduzindo drasticamente a dimensionalidade.\n",
        "\n",
        "3. Dropout:\n",
        "\n",
        "    * Aplica uma taxa de dropout de 40% para evitar overfitting, desativando aleatoriamente neurônios durante o treinamento.\n",
        "\n",
        "4. Camada Densa Final:\n",
        "\n",
        "    * Aplica uma camada densa com 10 neurônios e ativação softmax para produzir a distribuição de probabilidade sobre as 10 classes do CIFAR-10."
      ],
      "metadata": {
        "id": "K12O7p3-du6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Terceiro Módulo Inception"
      ],
      "metadata": {
        "id": "_Mlpe4aueGGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = inception_module(x, filters_1x1=256, filters_3x3_reduce=160, filters_3x3=320, filters_5x5_reduce=32, filters_5x5=128, filters_pool_proj=128, name='inception_5a')"
      ],
      "metadata": {
        "id": "DiLKaaI0bt8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* `inception_module`: Chama a função inception_module para criar e aplicar um módulo de Inception à entrada `x`.\n",
        "* `filters_1x1=256`: Define 256 filtros para a convolução 1x1.\n",
        "* `filters_3x3_reduce=160`: Define 160 filtros para a camada de redução antes da convolução 3x3.\n",
        "* `filters_3x3=320`: Define 320 filtros para a convolução 3x3.\n",
        "* `filters_5x5_reduce=32`: Define 32 filtros para a camada de redução antes da convolução 5x5.\n",
        "* `filters_5x5=128`: Define 128 filtros para a convolução 5x5.\n",
        "* `filters_pool_proj=128`: Define 128 filtros para a projeção após a camada de pooling.\n",
        "* `name='inception_5a'`: Define o nome do módulo como `'inception_5a'`.\n",
        "\n",
        "Este módulo de Inception combina várias convoluções (1x1, 3x3 com redução, 5x5 com redução) e pooling seguido de uma projeção (convolução 1x1), concatenando suas saídas."
      ],
      "metadata": {
        "id": "PKWnEN8qeEbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quarto Módulo Inception"
      ],
      "metadata": {
        "id": "QIf56TVue4Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = inception_module(x, filters_1x1=384, filters_3x3_reduce=192, filters_3x3=384, filters_5x5_reduce=48, filters_5x5=128, filters_pool_proj=128, name='inception_5b')"
      ],
      "metadata": {
        "id": "Z1CLM1Ybe39Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `filters_1x1=384`: Define 384 filtros para a convolução 1x1.\n",
        "* `filters_3x3_reduce=192`: Define 192 filtros para a camada de redução antes da convolução 3x3.\n",
        "* `filters_3x3=384`: Define 384 filtros para a convolução 3x3.\n",
        "* `filters_5x5_reduce=48`: Define 48 filtros para a camada de redução antes da convolução 5x5.\n",
        "* `filters_5x5=128`: Define 128 filtros para a convolução 5x5.\n",
        "* `filters_pool_proj=128`: Define 128 filtros para a projeção após a camada de pooling.\n",
        "* `name='inception_5b'`: Define o nome do módulo como `'inception_5b'`.\n",
        "\n",
        "Assim como os módulos anteriores, este módulo de Inception combina várias convoluções e pooling para extrair características em diferentes escalas."
      ],
      "metadata": {
        "id": "uiBnLrxte4q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global average pooling"
      ],
      "metadata": {
        "id": "Gg2MTn6ZkACA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)"
      ],
      "metadata": {
        "id": "bTV_FdtDfCGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `GlobalAveragePooling2D`: Aplica uma operação de pooling médio global.\n",
        "Em vez de usar uma janela deslizante, essa camada calcula a média de cada mapa de características inteiro.\n",
        "* `name='avg_pool_5_3x3/1'`: Nome da camada.\n",
        "* `(x)`: Aplica a operação de pooling ao tensor x resultante do módulo de Inception anterior.\n",
        "\n",
        "A operação de pooling médio global reduz cada mapa de características a um único valor (a média), resultando em um vetor de saída com uma dimensão por canal. Isso ajuda a reduzir drasticamente a dimensionalidade, preparando os dados para a camada densa final."
      ],
      "metadata": {
        "id": "Kt-zyRFSkKAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "2Oh_k3v2ke8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dropout(0.2)(x)"
      ],
      "metadata": {
        "id": "Y5NX93HtkKTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Dropout`: Aplica uma camada de dropout, que desativa aleatoriamente uma fração dos neurônios durante o treinamento para evitar overfitting.\n",
        "* `0.4`: Taxa de dropout (40% dos neurônios são desativados aleatoriamente).\n",
        "* `(x)`: Aplica a camada de dropout ao tensor x resultante da operação de pooling médio global."
      ],
      "metadata": {
        "id": "JRtAEAx2kiRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dense"
      ],
      "metadata": {
        "id": "lNXN2_Kakpri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Dense(10, activation='softmax', name='output')(x)"
      ],
      "metadata": {
        "id": "2akRx2IBksP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Dense`: Aplica uma camada totalmente conectada (densa).\n",
        "* `10`: Número de neurônios na camada de saída, correspondente ao número de classes no CIFAR-10.\n",
        "* `activation='softmax'`: Função de ativação softmax, que converte os valores dos neurônios em probabilidades, uma para cada classe.\n",
        "* `name='output'`: Nome da camada de saída.\n",
        "* `(x)`: Aplica a camada densa ao tensor x resultante da camada de dropout."
      ],
      "metadata": {
        "id": "K2Nr0F-1ks_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do Modelo Final com Saídas Principais e Auxiliares"
      ],
      "metadata": {
        "id": "OYJxl3LqdjMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Propósito do Modelo com Saídas Auxiliares**\n",
        "\n",
        "**Saída Principal `(x)`**\n",
        "\n",
        "A saída principal do modelo (x) é responsável por produzir a previsão final sobre as classes do CIFAR-10. Passa por várias camadas convolucionais, módulos de Inception, pooling e uma camada densa com softmax. É a saída usada para inferência (previsões) após o modelo ser treinado.\n",
        "\n",
        "**Saída Auxiliar `(x1)`**\n",
        "\n",
        "A saída auxiliar (x1) é usada durante o treinamento para ajudar a rede a aprender melhor. Ao adicionar uma perda auxiliar, o modelo recebe gradientes adicionais nas camadas intermediárias, o que pode ajudar a:\n",
        "\n",
        "* Mitigar o problema de gradientes desvanecentes: Aumenta a estabilidade do treinamento em redes profundas.\n",
        "* Acelerar a convergência: Proporciona uma maneira adicional de ajustar os pesos nas camadas intermediárias."
      ],
      "metadata": {
        "id": "zAZMu6Q4lyN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o modelo final com as saídas principais e auxiliares\n",
        "model = Model(input_layer, [x, x1], name='inception_v1')"
      ],
      "metadata": {
        "id": "Uuximf2paTpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. `Model`: A função Model da API funcional do Keras é usada para criar um modelo.\n",
        "\n",
        "2. `input_layer`: Este é o tensor de entrada do modelo, definido anteriormente como:\n",
        "```\n",
        "input_layer = Input(shape=(32, 32, 3))\n",
        "```\n",
        "Isso especifica que o modelo espera receber imagens de entrada com forma 32x32 pixels e 3 canais (RGB).\n",
        "\n",
        "3. `[x, x1]`: Esta é uma lista de tensores de saída do modelo. Vamos detalhar esses tensores:\n",
        "\n",
        "    * `x`: Este é o tensor da saída principal do modelo, que passa por vários módulos de Inception, pooling médio global, dropout, e uma camada densa final com softmax. Representa a previsão principal do modelo.\n",
        "    * `x1`: Este é o tensor da saída auxiliar, que passa por pooling, convolução 1x1, flatten, camada densa, dropout, e uma camada densa final com softmax. Representa uma previsão auxiliar usada durante o treinamento para fornecer gradientes adicionais.\n",
        "4. `name='inception_v1'`: Este é o nome do modelo, que pode ser usado para identificar o modelo posteriormente. Aqui, é nomeado como 'inception_v1'."
      ],
      "metadata": {
        "id": "6OTxpsU6lRYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Completo"
      ],
      "metadata": {
        "id": "QKB-eL0Yk--o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao combinar essas saídas, o modelo final é criado para:\n",
        "\n",
        "* Receber imagens de entrada com forma 32x32x3.\n",
        "* Produzir previsões através da saída principal `(x)` e auxiliar `(x1)`.\n",
        "* Durante o treinamento, ambas as saídas são usadas para calcular a perda total e ajustar os pesos.\n",
        "* Durante a inferência, apenas a saída principal é usada para fazer previsões."
      ],
      "metadata": {
        "id": "JY9tjn2qmLEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualização Simplificada do Modelo"
      ],
      "metadata": {
        "id": "6YE6Sn3ImTuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Input Layer (32x32x3)\n",
        "       |\n",
        "       v\n",
        "Convoluções, Pooling, Inception Modules, etc.\n",
        "       |\n",
        "       |-------------------------------------|\n",
        "       |                                     |\n",
        "       v                                     v\n",
        "Main Output (x)                          Auxiliary Output (x1)\n",
        "  (Softmax)                                (Softmax)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "gIZw71ibmggx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Input Layer`: Recebe a imagem de entrada.\n",
        "* `Bloco de Processamento`: Inclui todas as camadas convolucionais, módulos de Inception, pooling, etc.\n",
        "* `Main Output (x)`: Saída principal com softmax para prever classes.\n",
        "* `Auxiliary Output (x1)`: Saída auxiliar com softmax para prever classes, usada durante o treinamento."
      ],
      "metadata": {
        "id": "LNwPeIflmHxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumo da arquitetura do modelo\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Vjels-wAaUb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a54025f-2a58-4780-bd85-4747ee96e903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv_1_7x7div2 (Conv2D)     (None, 16, 16, 64)           9472      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pool_1_3x3div2 (MaxPoo  (None, 8, 8, 64)             0         ['conv_1_7x7div2[0][0]']      \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv_2a_3x3div1 (Conv2D)    (None, 8, 8, 64)             4160      ['max_pool_1_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " conv_2b_3x3div1 (Conv2D)    (None, 8, 8, 192)            110784    ['conv_2a_3x3div1[0][0]']     \n",
            "                                                                                                  \n",
            " max_pool_2_3x3div2 (MaxPoo  (None, 4, 4, 192)            0         ['conv_2b_3x3div1[0][0]']     \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 4, 4, 96)             18528     ['max_pool_2_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 16)             3088      ['max_pool_2_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 4, 4, 192)            0         ['max_pool_2_3x3div2[0][0]']  \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 4, 4, 64)             12352     ['max_pool_2_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)            110720    ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 4, 4, 32)             12832     ['conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 32)             6176      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " inception_3a (Concatenate)  (None, 4, 4, 256)            0         ['conv2d[0][0]',              \n",
            "                                                                     'conv2d_2[0][0]',            \n",
            "                                                                     'conv2d_4[0][0]',            \n",
            "                                                                     'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 128)            32896     ['inception_3a[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 32)             8224      ['inception_3a[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 256)            0         ['inception_3a[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 4, 4, 128)            32896     ['inception_3a[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 192)            221376    ['conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 4, 4, 96)             76896     ['conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 4, 4, 64)             16448     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " inception_3b (Concatenate)  (None, 4, 4, 480)            0         ['conv2d_6[0][0]',            \n",
            "                                                                     'conv2d_8[0][0]',            \n",
            "                                                                     'conv2d_10[0][0]',           \n",
            "                                                                     'conv2d_11[0][0]']           \n",
            "                                                                                                  \n",
            " max_pool_3_3x3div2 (MaxPoo  (None, 2, 2, 480)            0         ['inception_3b[0][0]']        \n",
            " ling2D)                                                                                          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 2, 2, 160)            76960     ['max_pool_3_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 2, 2, 32)             15392     ['max_pool_3_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 480)            0         ['max_pool_3_3x3div2[0][0]']  \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 2, 2, 256)            123136    ['max_pool_3_3x3div2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 2, 2, 320)            461120    ['conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 2, 2, 128)            102528    ['conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 2, 2, 128)            61568     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " inception_5a (Concatenate)  (None, 2, 2, 832)            0         ['conv2d_13[0][0]',           \n",
            "                                                                     'conv2d_15[0][0]',           \n",
            "                                                                     'conv2d_17[0][0]',           \n",
            "                                                                     'conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 2, 2, 192)            159936    ['inception_5a[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 2, 2, 48)             39984     ['inception_5a[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 832)            0         ['inception_5a[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 1, 1, 480)            0         ['max_pool_3_3x3div2[0][0]']  \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 2, 2, 384)            319872    ['inception_5a[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 2, 2, 384)            663936    ['conv2d_20[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 2, 2, 128)            153728    ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 2, 2, 128)            106624    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 1, 1, 128)            61568     ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " inception_5b (Concatenate)  (None, 2, 2, 1024)           0         ['conv2d_19[0][0]',           \n",
            "                                                                     'conv2d_21[0][0]',           \n",
            "                                                                     'conv2d_23[0][0]',           \n",
            "                                                                     'conv2d_24[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 128)                  0         ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " avg_pool_5_3x3/1 (GlobalAv  (None, 1024)                 0         ['inception_5b[0][0]']        \n",
            " eragePooling2D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 2048)                 264192    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 1024)                 0         ['avg_pool_5_3x3/1[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 2048)                 0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 10)                   10250     ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " auxilliary_output_1 (Dense  (None, 10)                   20490     ['dropout[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3318132 (12.66 MB)\n",
            "Trainable params: 3318132 (12.66 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parâmetros de treinamento"
      ],
      "metadata": {
        "id": "P6xaWXYroLx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parâmetros de treinamento\n",
        "epochs = 100\n",
        "initial_lrate = 0.01"
      ],
      "metadata": {
        "id": "zR6XgLAHb3t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Função de decaimento da Taxa de Aprendizado"
      ],
      "metadata": {
        "id": "jIaVKSeFoOoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A taxa de aprendizado é um hiperparâmetro crucial no treinamento de redes neurais. Ajustar a taxa de aprendizado ao longo do treinamento pode ajudar a melhorar a convergência do modelo. A função `decay` abaixo implementa uma estratégia de decaimento da taxa de aprendizado.\n",
        "\n",
        "**Estratégia de Decaimento**\n",
        "\n",
        "A estratégia de decaimento utilizada aqui é conhecida como **decaimento exponencial em etapas**. A cada epochs_drop épocas, a taxa de aprendizado é multiplicada por um fator drop (0.96). Isso significa que a taxa de aprendizado diminui exponencialmente ao longo do tempo, o que pode ajudar o modelo a convergir de forma mais estável e evitar sobreajustes."
      ],
      "metadata": {
        "id": "s620V66EoW_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função de decaimento da taxa de aprendizado\n",
        "def decay(epoch):\n",
        "    drop = 0.96\n",
        "    epochs_drop = 5\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate"
      ],
      "metadata": {
        "id": "JgM6KHfCaZdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `epoch`: O número atual da época (ou iteração) do treinamento.\n",
        "* `drop = 0.96`: Define a taxa de decaimento. Isso significa que a taxa de aprendizado será multiplicada por 0.96 a cada período definido por epochs_drop.\n",
        "* `epochs_drop = 8`: Define o número de épocas após o qual a taxa de aprendizado será ajustada (decairá).\n",
        "\n",
        "Cálculo da nova Taxa de Aprendizado:\n",
        "\n",
        "```\n",
        "lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))\n",
        "```\n",
        "* `initial_lrate`: Supõe-se que initial_lrate seja a taxa de aprendizado inicial definida fora da função (no seu caso, 0.01).\n",
        "* `math.pow(drop, math.floor((1 + epoch) / epochs_drop))`: Calcula o fator de decaimento da taxa de aprendizado:\n",
        "    * `math.floor((1 + epoch) / epochs_drop)`: Divide o número atual da época pelo número de épocas para o decaimento e arredonda para baixo (função piso). Isso conta quantas vezes a taxa de aprendizado deve decair até a época atual.\n",
        "    * `math.pow(drop, ...)`: Eleva drop (0.96) à potência do número de vezes que a taxa de aprendizado deve decair.\n",
        "    * Multiplica `initial_lrate` pelo fator de decaimento: Isso ajusta a taxa de aprendizado com base no número de épocas transcorridas."
      ],
      "metadata": {
        "id": "I5V5ob_bqCEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do Otimizador e Callback de Decaimento da Taxa de Aprendizado"
      ],
      "metadata": {
        "id": "qU9mudrLnOiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parâmetros do Otimizador\n",
        "\n",
        "Para o conjunto de dados CIFAR-10, o Adam é frequentemente recomendado devido à sua capacidade de ajustar dinamicamente a taxa de aprendizado e convergir rapidamente. No entanto, SGD com momentum é outra escolha excelente e frequentemente usada em arquiteturas de rede profundas, como ResNet e VGG, devido ao seu controle e desempenho estáveis."
      ],
      "metadata": {
        "id": "VLm6tOnxrLZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para implementação com SGD (Stochacstic Gradient Descent)"
      ],
      "metadata": {
        "id": "N3X0gLVusRAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SGD com Momentum**\n",
        "\n",
        "* Vantagens:\n",
        "    * Simplicidade e controle.\n",
        "    * Bom desempenho em muitos problemas de visão computacional.\n",
        "    * O momentum ajuda a acelerar a convergência e a evitar mínimos locais.\n",
        "* Desvantagens:\n",
        "    * Requer ajuste manual da taxa de aprendizado.\n",
        "    * Pode ser mais lento na convergência inicial em comparação com otimizadores adaptativos."
      ],
      "metadata": {
        "id": "AhBwTpfKtQvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = SGD(learning_rate=initial_lrate, momentum=0.9, nesterov=False)"
      ],
      "metadata": {
        "id": "suqJPDIkcDUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. SGD: Importa e configura o otimizador Stochastic Gradient Descent (SGD). O SGD é um dos otimizadores mais populares em redes neurais devido à sua simplicidade e eficiência em muitos problemas de aprendizado.\n",
        "\n",
        "2. Parâmetros do SGD:\n",
        "\n",
        "    * `learning_rate=initial_lrate`: Define a taxa de aprendizado inicial do otimizador. No seu caso, initial_lrate foi definido como 0.01. A taxa de aprendizado controla o tamanho dos passos dados durante a descida do gradiente, ou seja, quão grandes são as atualizações feitas nos pesos da rede em cada iteração.\n",
        "    * `momentum=0.9`: O termo momentum é usado para acelerar o treinamento e ajudar a evitar mínimos locais. O valor 0.9 indica que 90% do gradiente anterior é usado para suavizar a trajetória do treinamento.\n",
        "    * `nesterov=False`: Nesterov momentum é uma variação do método de momentum que pode levar a uma convergência mais rápida. Aqui, está configurado como False, indicando que o momentum padrão está sendo usado."
      ],
      "metadata": {
        "id": "vv-G6PrKs62Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para implementação com Rmsprop"
      ],
      "metadata": {
        "id": "Z3OX6QfutiSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Vantagens:**\n",
        "    * Taxas de aprendizado adaptativas.\n",
        "    * Eficaz em problemas onde as taxas de aprendizado precisam ser ajustadas dinamicamente.\n",
        "    * Boa convergência em problemas de visão computacional.\n",
        "* **Desvantagens:**\n",
        "    * Pode precisar de ajuste cuidadoso dos hiperparâmetros."
      ],
      "metadata": {
        "id": "ri6qmv4itk8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = RMSprop(learning_rate=initial_lrate)"
      ],
      "metadata": {
        "id": "0ch-AbBVuCnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Para implementação com Adam"
      ],
      "metadata": {
        "id": "OdjscBLOuM_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Vantagens:**\n",
        "\n",
        "* Combina as vantagens de dois outros otimizadores: AdaGrad e RMSprop.\n",
        "Taxas de aprendizado adaptativas, ajustando automaticamente.\n",
        "* Geralmente requer menos ajuste manual.\n",
        "* Convergência rápida e eficiente.\n",
        "\n",
        "* **Desvantagens:**\n",
        "* Pode ser mais sensível à escolha de hiperparâmetros como taxa de aprendizado inicial.\n",
        "* Pode, em alguns casos, sobreajustar em conjuntos de dados ruidosos."
      ],
      "metadata": {
        "id": "6p5SiQ9UuQ7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim = Adam(learning_rate=initial_lrate)"
      ],
      "metadata": {
        "id": "D-nOBNueuegX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callback de Decaimento da Taxa de Aprendizado"
      ],
      "metadata": {
        "id": "2q8o9cA5sdAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_sc = LearningRateScheduler(decay, verbose=1)"
      ],
      "metadata": {
        "id": "Hn3h3Qs-scVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. `LearningRateScheduler`: Importa e configura o callback LearningRateScheduler do Keras, que ajusta a taxa de aprendizado durante o treinamento com base em uma função definida pelo usuário.\n",
        "\n",
        "2. Parâmetros do `LearningRateScheduler`:\n",
        "\n",
        "    * `decay`: Passa a função decay definida anteriormente, que calcula a nova taxa de aprendizado com base na época atual. Esta função é chamada no início de cada época para ajustar a taxa de aprendizado.\n",
        "    * `verbose=1`: Define o nível de verbosidade. Quando verbose=1, o callback imprimirá a nova taxa de aprendizado no início de cada época, permitindo que você monitore como a taxa de aprendizado está mudando ao longo do tempo."
      ],
      "metadata": {
        "id": "NlOg5EvRsrwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilação do modelo"
      ],
      "metadata": {
        "id": "KGaJvoUIrJJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
        "    loss_weights=[1, 0.3],\n",
        "    optimizer=optim,\n",
        "    metrics=[['accuracy'], ['accuracy']]\n",
        ")"
      ],
      "metadata": {
        "id": "2N295NUecH8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `loss`\n",
        "```\n",
        "loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
        "```"
      ],
      "metadata": {
        "id": "TgItzT4Jvtz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Especifica as funções de perda a serem usadas para cada uma das saídas do modelo.\n",
        "* `categorical_crossentropy`: É uma função de perda usada para problemas de classificação multi-classe, onde as classes são mutuamente exclusivas.\n",
        "* A primeira função de perda se aplica à saída principal do modelo (saída x).\n",
        "* A segunda função de perda se aplica à saída auxiliar do modelo (saída x1)."
      ],
      "metadata": {
        "id": "AjpRkLkFzeJR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Considerações**\n",
        "\n",
        "* **Escolha da Perda:** A escolha da função de perda depende das características específicas do problema e dos dados. `categorical_crossentropy` e `sparse_categorical_crossentropy` são geralmente as melhores escolhas para problemas de classificação multi-classe.\n",
        "* **Performance:** A função de perda escolhida pode impactar a convergência e a performance final do modelo. Experimentar com diferentes funções de perda pode ajudar a encontrar a melhor opção para seu problema específico.\n",
        "* **Métricas:** A métrica `accuracy` é adequada para problemas de classificação, mas você pode também experimentar outras métricas como `top_k_categorical_accuracy` para avaliar a performance em problemas onde múltiplas classes são relevantes.\n",
        "\n",
        "Ao experimentar diferentes funções de perda, você pode observar como cada uma afeta o treinamento e a performance do seu modelo, permitindo ajustar e otimizar conforme necessário."
      ],
      "metadata": {
        "id": "JJ00VIbuyG1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Outras funções de loss"
      ],
      "metadata": {
        "id": "uftY4AQXwKm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 1. Sparse Categorical Crossentropy\n",
        "\n",
        "A sparse_categorical_crossentropy é útil quando as etiquetas são fornecidas como inteiros em vez de vetores one-hot.\n",
        "\n",
        "```\n",
        "loss='sparse_categorical_crossentropy'\n",
        "```\n",
        "\n",
        "* Semelhante à `categorical_crossentropy`, mas aceita etiquetas inteiras em vez de vetores one-hot.\n",
        "* Pode ser mais eficiente em termos de memória e tempo de processamento, especialmente para grandes conjuntos de dados."
      ],
      "metadata": {
        "id": "w_28NuQ7wTpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 2. Mean Squared Error (MSE)\n",
        "\n",
        "Embora seja mais comumente usada para problemas de regressão, a `mean_squared_error` também pode ser usada para classificação em certas situações.\n",
        "\n",
        "```\n",
        "loss='mean_squared_error'\n",
        "```\n",
        "\n",
        "* Calcula a média dos quadrados das diferenças entre as previsões e as verdadeiras etiquetas.\n",
        "* Pode ser útil em situações onde se deseja penalizar fortemente grandes erros, mas não é a escolha padrão para classificação."
      ],
      "metadata": {
        "id": "nyRsKzl_wmJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 3. Hinge Loss\n",
        "\n",
        "A `hinge` loss é frequentemente usada para classificadores de margem, como SVMs, mas também pode ser aplicada em redes neurais.\n",
        "\n",
        "```\n",
        "loss='hinge'\n",
        "```\n",
        "\n",
        "* Penaliza previsões incorretas que estão além da margem de decisão.\n",
        "* Pode ser adaptada para classificadores binários e multi-classe."
      ],
      "metadata": {
        "id": "AN3s0-6QxM7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 4. Categorical Hinge\n",
        "\n",
        "A `categorical_hinge` é uma extensão da hinge loss para problemas de classificação multi-classe.\n",
        "\n",
        "```\n",
        "loss='categorical_hinge'\n",
        "```\n",
        "\n",
        "* Penaliza a diferença entre a previsão correta e a maior previsão incorreta.\n",
        "* Pode ser mais robusta a outliers em alguns cenários de classificação."
      ],
      "metadata": {
        "id": "jvWluISsxdnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 5. Kullback-Leibler Divergence (KL Divergence)\n",
        "\n",
        "A `kullback_leibler_divergence` mede a diferença entre duas distribuições de probabilidade.\n",
        "\n",
        "```\n",
        "loss='kullback_leibler_divergence'\n",
        "```\n",
        "\n",
        "* Útil em situações onde se está comparando distribuições de probabilidade.\n",
        "* Pode ser usada quando as saídas do modelo são distribuições de probabilidade."
      ],
      "metadata": {
        "id": "aJ5rAQBSxt56"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `loss_weights`\n",
        "\n",
        "```\n",
        "loss_weights=[1, 0.3],\n",
        "```"
      ],
      "metadata": {
        "id": "ONjXwbNgwPHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Especifica os pesos atribuídos a cada uma das perdas no cálculo da perda total.\n",
        "    * `1`: A perda associada à saída principal tem um peso de 1.\n",
        "    * `0.3`: A perda associada à saída auxiliar tem um peso de 0.3.\n",
        "* Isso significa que a perda da saída auxiliar contribui com 30% da perda total, enquanto a perda da saída principal contribui com 100% da perda total.\n",
        "* A razão para usar pesos diferentes é que a saída auxiliar é usada principalmente para ajudar no treinamento das camadas intermediárias e não deve dominar a perda total."
      ],
      "metadata": {
        "id": "G_3gZOoBzZvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `optimizer`\n",
        "\n",
        "```\n",
        "optimizer=optim,\n",
        "```"
      ],
      "metadata": {
        "id": "IgIdyO59y-O1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Especifica o otimizador a ser usado durante o treinamento do modelo.\n",
        "* Para este exemplo, foram codificados:\n",
        "    * SGD com Momentum\n",
        "    ```\n",
        "    optim = SGD(learning_rate=initial_lrate, momentum=0.9, nesterov=False)\n",
        "    ```\n",
        "    * Rmsprop\n",
        "    ```\n",
        "    optim = RMSprop(learning_rate=initial_lrate)\n",
        "    ```\n",
        "    * Adam\n",
        "    ```\n",
        "    optim = Adam(learning_rate=initial_lrate)\n",
        "    ```"
      ],
      "metadata": {
        "id": "kvm2XLklzjdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `metrics`\n",
        "\n",
        "```\n",
        "metrics=[['accuracy'], ['accuracy']]\n",
        "```"
      ],
      "metadata": {
        "id": "ykbswwQX0QKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Especifica as métricas a serem calculadas para cada uma das saídas do modelo.\n",
        "* `[['accuracy'], ['accuracy']]`: Indica que a acurácia será calculada para ambas as saídas, a principal e a auxiliar.\n",
        "* A acurácia é uma métrica comum para problemas de classificação, representando a proporção de previsões corretas em relação ao total de previsões."
      ],
      "metadata": {
        "id": "3DypqheB0Y4Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do modelo"
      ],
      "metadata": {
        "id": "UVg_g0Wh1Iq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/gpu:0'):\n",
        "    model.fit(X_train, [y_train, y_train], validation_data=(X_test, [y_test, y_test]), epochs=epochs, batch_size=512, callbacks=[lr_sc])"
      ],
      "metadata": {
        "id": "wSK_24BxlBa-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e66b3ce-6a3a-4e26-c85d-3dfff70a4ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 1/100\n",
            "98/98 [==============================] - 29s 116ms/step - loss: 14.4494 - output_loss: 13.6045 - auxilliary_output_1_loss: 2.8164 - output_accuracy: 0.1220 - auxilliary_output_1_accuracy: 0.1253 - val_loss: 2.7796 - val_output_loss: 2.1376 - val_auxilliary_output_1_loss: 2.1400 - val_output_accuracy: 0.1676 - val_auxilliary_output_1_accuracy: 0.1722 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 2/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 2.6710 - output_loss: 2.0527 - auxilliary_output_1_loss: 2.0608 - output_accuracy: 0.2254 - auxilliary_output_1_accuracy: 0.2200 - val_loss: 2.5159 - val_output_loss: 1.9322 - val_auxilliary_output_1_loss: 1.9454 - val_output_accuracy: 0.2937 - val_auxilliary_output_1_accuracy: 0.2731 - lr: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 3/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 2.4581 - output_loss: 1.8883 - auxilliary_output_1_loss: 1.8995 - output_accuracy: 0.2978 - auxilliary_output_1_accuracy: 0.2921 - val_loss: 2.3680 - val_output_loss: 1.8193 - val_auxilliary_output_1_loss: 1.8291 - val_output_accuracy: 0.3246 - val_auxilliary_output_1_accuracy: 0.3174 - lr: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.01.\n",
            "Epoch 4/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 2.3295 - output_loss: 1.7864 - auxilliary_output_1_loss: 1.8105 - output_accuracy: 0.3446 - auxilliary_output_1_accuracy: 0.3311 - val_loss: 2.2452 - val_output_loss: 1.7207 - val_auxilliary_output_1_loss: 1.7485 - val_output_accuracy: 0.3696 - val_auxilliary_output_1_accuracy: 0.3585 - lr: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 5/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 2.1975 - output_loss: 1.6869 - auxilliary_output_1_loss: 1.7019 - output_accuracy: 0.3843 - auxilliary_output_1_accuracy: 0.3772 - val_loss: 2.1242 - val_output_loss: 1.6272 - val_auxilliary_output_1_loss: 1.6568 - val_output_accuracy: 0.4131 - val_auxilliary_output_1_accuracy: 0.3997 - lr: 0.0096\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 6/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 2.1092 - output_loss: 1.6184 - auxilliary_output_1_loss: 1.6361 - output_accuracy: 0.4117 - auxilliary_output_1_accuracy: 0.4028 - val_loss: 2.0479 - val_output_loss: 1.5735 - val_auxilliary_output_1_loss: 1.5813 - val_output_accuracy: 0.4257 - val_auxilliary_output_1_accuracy: 0.4217 - lr: 0.0096\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 7/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 2.0434 - output_loss: 1.5675 - auxilliary_output_1_loss: 1.5862 - output_accuracy: 0.4320 - auxilliary_output_1_accuracy: 0.4267 - val_loss: 2.0826 - val_output_loss: 1.5999 - val_auxilliary_output_1_loss: 1.6091 - val_output_accuracy: 0.4168 - val_auxilliary_output_1_accuracy: 0.4116 - lr: 0.0096\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 8/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.9835 - output_loss: 1.5211 - auxilliary_output_1_loss: 1.5415 - output_accuracy: 0.4498 - auxilliary_output_1_accuracy: 0.4434 - val_loss: 1.9980 - val_output_loss: 1.5328 - val_auxilliary_output_1_loss: 1.5505 - val_output_accuracy: 0.4381 - val_auxilliary_output_1_accuracy: 0.4272 - lr: 0.0096\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0096.\n",
            "Epoch 9/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.9658 - output_loss: 1.5063 - auxilliary_output_1_loss: 1.5315 - output_accuracy: 0.4581 - auxilliary_output_1_accuracy: 0.4463 - val_loss: 1.9642 - val_output_loss: 1.5057 - val_auxilliary_output_1_loss: 1.5282 - val_output_accuracy: 0.4522 - val_auxilliary_output_1_accuracy: 0.4449 - lr: 0.0096\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 10/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.9138 - output_loss: 1.4658 - auxilliary_output_1_loss: 1.4933 - output_accuracy: 0.4712 - auxilliary_output_1_accuracy: 0.4612 - val_loss: 1.9365 - val_output_loss: 1.4841 - val_auxilliary_output_1_loss: 1.5082 - val_output_accuracy: 0.4620 - val_auxilliary_output_1_accuracy: 0.4512 - lr: 0.0092\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 11/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.8745 - output_loss: 1.4344 - auxilliary_output_1_loss: 1.4670 - output_accuracy: 0.4808 - auxilliary_output_1_accuracy: 0.4678 - val_loss: 1.9714 - val_output_loss: 1.5117 - val_auxilliary_output_1_loss: 1.5325 - val_output_accuracy: 0.4630 - val_auxilliary_output_1_accuracy: 0.4558 - lr: 0.0092\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 12/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.8661 - output_loss: 1.4277 - auxilliary_output_1_loss: 1.4615 - output_accuracy: 0.4849 - auxilliary_output_1_accuracy: 0.4704 - val_loss: 1.9048 - val_output_loss: 1.4634 - val_auxilliary_output_1_loss: 1.4716 - val_output_accuracy: 0.4701 - val_auxilliary_output_1_accuracy: 0.4642 - lr: 0.0092\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 13/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.8489 - output_loss: 1.4144 - auxilliary_output_1_loss: 1.4482 - output_accuracy: 0.4894 - auxilliary_output_1_accuracy: 0.4756 - val_loss: 1.9190 - val_output_loss: 1.4688 - val_auxilliary_output_1_loss: 1.5009 - val_output_accuracy: 0.4658 - val_auxilliary_output_1_accuracy: 0.4542 - lr: 0.0092\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.009216.\n",
            "Epoch 14/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.8119 - output_loss: 1.3842 - auxilliary_output_1_loss: 1.4256 - output_accuracy: 0.4998 - auxilliary_output_1_accuracy: 0.4862 - val_loss: 1.9034 - val_output_loss: 1.4600 - val_auxilliary_output_1_loss: 1.4781 - val_output_accuracy: 0.4691 - val_auxilliary_output_1_accuracy: 0.4621 - lr: 0.0092\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 15/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.7898 - output_loss: 1.3672 - auxilliary_output_1_loss: 1.4088 - output_accuracy: 0.5097 - auxilliary_output_1_accuracy: 0.4918 - val_loss: 2.0084 - val_output_loss: 1.5370 - val_auxilliary_output_1_loss: 1.5714 - val_output_accuracy: 0.4539 - val_auxilliary_output_1_accuracy: 0.4446 - lr: 0.0088\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 16/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.7627 - output_loss: 1.3454 - auxilliary_output_1_loss: 1.3912 - output_accuracy: 0.5120 - auxilliary_output_1_accuracy: 0.5008 - val_loss: 1.9705 - val_output_loss: 1.5081 - val_auxilliary_output_1_loss: 1.5414 - val_output_accuracy: 0.4608 - val_auxilliary_output_1_accuracy: 0.4523 - lr: 0.0088\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 17/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.7532 - output_loss: 1.3377 - auxilliary_output_1_loss: 1.3851 - output_accuracy: 0.5163 - auxilliary_output_1_accuracy: 0.5011 - val_loss: 1.9290 - val_output_loss: 1.4809 - val_auxilliary_output_1_loss: 1.4937 - val_output_accuracy: 0.4709 - val_auxilliary_output_1_accuracy: 0.4599 - lr: 0.0088\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 18/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.7351 - output_loss: 1.3229 - auxilliary_output_1_loss: 1.3741 - output_accuracy: 0.5246 - auxilliary_output_1_accuracy: 0.5023 - val_loss: 1.8798 - val_output_loss: 1.4378 - val_auxilliary_output_1_loss: 1.4733 - val_output_accuracy: 0.4839 - val_auxilliary_output_1_accuracy: 0.4679 - lr: 0.0088\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.008847359999999999.\n",
            "Epoch 19/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.7081 - output_loss: 1.3010 - auxilliary_output_1_loss: 1.3572 - output_accuracy: 0.5335 - auxilliary_output_1_accuracy: 0.5126 - val_loss: 2.0103 - val_output_loss: 1.5444 - val_auxilliary_output_1_loss: 1.5529 - val_output_accuracy: 0.4620 - val_auxilliary_output_1_accuracy: 0.4507 - lr: 0.0088\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            "Epoch 20/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.7109 - output_loss: 1.3021 - auxilliary_output_1_loss: 1.3627 - output_accuracy: 0.5335 - auxilliary_output_1_accuracy: 0.5101 - val_loss: 1.8966 - val_output_loss: 1.4501 - val_auxilliary_output_1_loss: 1.4884 - val_output_accuracy: 0.4856 - val_auxilliary_output_1_accuracy: 0.4760 - lr: 0.0085\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            "Epoch 21/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.6790 - output_loss: 1.2763 - auxilliary_output_1_loss: 1.3423 - output_accuracy: 0.5391 - auxilliary_output_1_accuracy: 0.5150 - val_loss: 1.9193 - val_output_loss: 1.4781 - val_auxilliary_output_1_loss: 1.4707 - val_output_accuracy: 0.4772 - val_auxilliary_output_1_accuracy: 0.4697 - lr: 0.0085\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            "Epoch 22/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.6478 - output_loss: 1.2513 - auxilliary_output_1_loss: 1.3218 - output_accuracy: 0.5484 - auxilliary_output_1_accuracy: 0.5249 - val_loss: 1.8937 - val_output_loss: 1.4534 - val_auxilliary_output_1_loss: 1.4676 - val_output_accuracy: 0.4826 - val_auxilliary_output_1_accuracy: 0.4735 - lr: 0.0085\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            "Epoch 23/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.6411 - output_loss: 1.2461 - auxilliary_output_1_loss: 1.3167 - output_accuracy: 0.5534 - auxilliary_output_1_accuracy: 0.5281 - val_loss: 1.9527 - val_output_loss: 1.5007 - val_auxilliary_output_1_loss: 1.5067 - val_output_accuracy: 0.4668 - val_auxilliary_output_1_accuracy: 0.4575 - lr: 0.0085\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.008493465599999998.\n",
            "Epoch 24/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.6209 - output_loss: 1.2293 - auxilliary_output_1_loss: 1.3055 - output_accuracy: 0.5561 - auxilliary_output_1_accuracy: 0.5314 - val_loss: 1.9521 - val_output_loss: 1.4986 - val_auxilliary_output_1_loss: 1.5116 - val_output_accuracy: 0.4708 - val_auxilliary_output_1_accuracy: 0.4651 - lr: 0.0085\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            "Epoch 25/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.6010 - output_loss: 1.2147 - auxilliary_output_1_loss: 1.2878 - output_accuracy: 0.5630 - auxilliary_output_1_accuracy: 0.5357 - val_loss: 1.9606 - val_output_loss: 1.5111 - val_auxilliary_output_1_loss: 1.4980 - val_output_accuracy: 0.4795 - val_auxilliary_output_1_accuracy: 0.4776 - lr: 0.0082\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            "Epoch 26/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.5458 - output_loss: 1.1694 - auxilliary_output_1_loss: 1.2546 - output_accuracy: 0.5772 - auxilliary_output_1_accuracy: 0.5482 - val_loss: 1.9316 - val_output_loss: 1.4881 - val_auxilliary_output_1_loss: 1.4780 - val_output_accuracy: 0.4836 - val_auxilliary_output_1_accuracy: 0.4744 - lr: 0.0082\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            "Epoch 27/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.5694 - output_loss: 1.1862 - auxilliary_output_1_loss: 1.2775 - output_accuracy: 0.5725 - auxilliary_output_1_accuracy: 0.5427 - val_loss: 1.9918 - val_output_loss: 1.5301 - val_auxilliary_output_1_loss: 1.5390 - val_output_accuracy: 0.4630 - val_auxilliary_output_1_accuracy: 0.4555 - lr: 0.0082\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            "Epoch 28/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.5259 - output_loss: 1.1523 - auxilliary_output_1_loss: 1.2454 - output_accuracy: 0.5845 - auxilliary_output_1_accuracy: 0.5551 - val_loss: 2.0039 - val_output_loss: 1.5413 - val_auxilliary_output_1_loss: 1.5422 - val_output_accuracy: 0.4704 - val_auxilliary_output_1_accuracy: 0.4554 - lr: 0.0082\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.008153726976.\n",
            "Epoch 29/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.5223 - output_loss: 1.1477 - auxilliary_output_1_loss: 1.2486 - output_accuracy: 0.5866 - auxilliary_output_1_accuracy: 0.5534 - val_loss: 2.0948 - val_output_loss: 1.6093 - val_auxilliary_output_1_loss: 1.6182 - val_output_accuracy: 0.4563 - val_auxilliary_output_1_accuracy: 0.4450 - lr: 0.0082\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            "Epoch 30/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.5113 - output_loss: 1.1382 - auxilliary_output_1_loss: 1.2437 - output_accuracy: 0.5900 - auxilliary_output_1_accuracy: 0.5551 - val_loss: 2.0014 - val_output_loss: 1.5449 - val_auxilliary_output_1_loss: 1.5219 - val_output_accuracy: 0.4767 - val_auxilliary_output_1_accuracy: 0.4689 - lr: 0.0078\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            "Epoch 31/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.4922 - output_loss: 1.1234 - auxilliary_output_1_loss: 1.2292 - output_accuracy: 0.5943 - auxilliary_output_1_accuracy: 0.5588 - val_loss: 2.0383 - val_output_loss: 1.5689 - val_auxilliary_output_1_loss: 1.5647 - val_output_accuracy: 0.4763 - val_auxilliary_output_1_accuracy: 0.4592 - lr: 0.0078\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            "Epoch 32/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.4613 - output_loss: 1.0986 - auxilliary_output_1_loss: 1.2089 - output_accuracy: 0.6027 - auxilliary_output_1_accuracy: 0.5687 - val_loss: 2.0870 - val_output_loss: 1.6061 - val_auxilliary_output_1_loss: 1.6031 - val_output_accuracy: 0.4660 - val_auxilliary_output_1_accuracy: 0.4578 - lr: 0.0078\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            "Epoch 33/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.4542 - output_loss: 1.0927 - auxilliary_output_1_loss: 1.2047 - output_accuracy: 0.6071 - auxilliary_output_1_accuracy: 0.5690 - val_loss: 2.0139 - val_output_loss: 1.5507 - val_auxilliary_output_1_loss: 1.5442 - val_output_accuracy: 0.4718 - val_auxilliary_output_1_accuracy: 0.4627 - lr: 0.0078\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.007827577896959998.\n",
            "Epoch 34/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.4447 - output_loss: 1.0848 - auxilliary_output_1_loss: 1.1997 - output_accuracy: 0.6090 - auxilliary_output_1_accuracy: 0.5702 - val_loss: 2.1307 - val_output_loss: 1.6455 - val_auxilliary_output_1_loss: 1.6173 - val_output_accuracy: 0.4661 - val_auxilliary_output_1_accuracy: 0.4583 - lr: 0.0078\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
            "Epoch 35/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.3832 - output_loss: 1.0335 - auxilliary_output_1_loss: 1.1653 - output_accuracy: 0.6275 - auxilliary_output_1_accuracy: 0.5836 - val_loss: 2.0789 - val_output_loss: 1.6066 - val_auxilliary_output_1_loss: 1.5741 - val_output_accuracy: 0.4761 - val_auxilliary_output_1_accuracy: 0.4701 - lr: 0.0075\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
            "Epoch 36/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.3668 - output_loss: 1.0192 - auxilliary_output_1_loss: 1.1587 - output_accuracy: 0.6322 - auxilliary_output_1_accuracy: 0.5865 - val_loss: 2.1556 - val_output_loss: 1.6764 - val_auxilliary_output_1_loss: 1.5973 - val_output_accuracy: 0.4636 - val_auxilliary_output_1_accuracy: 0.4563 - lr: 0.0075\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
            "Epoch 37/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.3188 - output_loss: 0.9821 - auxilliary_output_1_loss: 1.1221 - output_accuracy: 0.6451 - auxilliary_output_1_accuracy: 0.5971 - val_loss: 2.1468 - val_output_loss: 1.6669 - val_auxilliary_output_1_loss: 1.5997 - val_output_accuracy: 0.4732 - val_auxilliary_output_1_accuracy: 0.4677 - lr: 0.0075\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
            "Epoch 38/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.3125 - output_loss: 0.9752 - auxilliary_output_1_loss: 1.1241 - output_accuracy: 0.6469 - auxilliary_output_1_accuracy: 0.5988 - val_loss: 2.1454 - val_output_loss: 1.6745 - val_auxilliary_output_1_loss: 1.5695 - val_output_accuracy: 0.4630 - val_auxilliary_output_1_accuracy: 0.4658 - lr: 0.0075\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.007514474781081598.\n",
            "Epoch 39/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.3500 - output_loss: 1.0063 - auxilliary_output_1_loss: 1.1456 - output_accuracy: 0.6402 - auxilliary_output_1_accuracy: 0.5892 - val_loss: 2.1509 - val_output_loss: 1.6708 - val_auxilliary_output_1_loss: 1.6003 - val_output_accuracy: 0.4621 - val_auxilliary_output_1_accuracy: 0.4593 - lr: 0.0075\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
            "Epoch 40/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.3785 - output_loss: 1.0278 - auxilliary_output_1_loss: 1.1691 - output_accuracy: 0.6305 - auxilliary_output_1_accuracy: 0.5847 - val_loss: 2.2272 - val_output_loss: 1.7368 - val_auxilliary_output_1_loss: 1.6348 - val_output_accuracy: 0.4645 - val_auxilliary_output_1_accuracy: 0.4558 - lr: 0.0072\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
            "Epoch 41/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.2687 - output_loss: 0.9382 - auxilliary_output_1_loss: 1.1017 - output_accuracy: 0.6653 - auxilliary_output_1_accuracy: 0.6075 - val_loss: 2.2491 - val_output_loss: 1.7619 - val_auxilliary_output_1_loss: 1.6239 - val_output_accuracy: 0.4604 - val_auxilliary_output_1_accuracy: 0.4598 - lr: 0.0072\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
            "Epoch 42/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.2332 - output_loss: 0.9094 - auxilliary_output_1_loss: 1.0795 - output_accuracy: 0.6737 - auxilliary_output_1_accuracy: 0.6136 - val_loss: 2.3684 - val_output_loss: 1.8530 - val_auxilliary_output_1_loss: 1.7182 - val_output_accuracy: 0.4621 - val_auxilliary_output_1_accuracy: 0.4565 - lr: 0.0072\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
            "Epoch 43/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.2066 - output_loss: 0.8886 - auxilliary_output_1_loss: 1.0599 - output_accuracy: 0.6814 - auxilliary_output_1_accuracy: 0.6213 - val_loss: 2.3172 - val_output_loss: 1.8205 - val_auxilliary_output_1_loss: 1.6559 - val_output_accuracy: 0.4648 - val_auxilliary_output_1_accuracy: 0.4605 - lr: 0.0072\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.007213895789838334.\n",
            "Epoch 44/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.1930 - output_loss: 0.8767 - auxilliary_output_1_loss: 1.0543 - output_accuracy: 0.6833 - auxilliary_output_1_accuracy: 0.6206 - val_loss: 2.3524 - val_output_loss: 1.8459 - val_auxilliary_output_1_loss: 1.6885 - val_output_accuracy: 0.4605 - val_auxilliary_output_1_accuracy: 0.4564 - lr: 0.0072\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
            "Epoch 45/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.1413 - output_loss: 0.8327 - auxilliary_output_1_loss: 1.0285 - output_accuracy: 0.7009 - auxilliary_output_1_accuracy: 0.6319 - val_loss: 2.3409 - val_output_loss: 1.8359 - val_auxilliary_output_1_loss: 1.6835 - val_output_accuracy: 0.4678 - val_auxilliary_output_1_accuracy: 0.4615 - lr: 0.0069\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
            "Epoch 46/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.1544 - output_loss: 0.8429 - auxilliary_output_1_loss: 1.0383 - output_accuracy: 0.6954 - auxilliary_output_1_accuracy: 0.6292 - val_loss: 2.5355 - val_output_loss: 2.0126 - val_auxilliary_output_1_loss: 1.7430 - val_output_accuracy: 0.4611 - val_auxilliary_output_1_accuracy: 0.4581 - lr: 0.0069\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
            "Epoch 47/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.1147 - output_loss: 0.8111 - auxilliary_output_1_loss: 1.0119 - output_accuracy: 0.7079 - auxilliary_output_1_accuracy: 0.6384 - val_loss: 2.4908 - val_output_loss: 1.9733 - val_auxilliary_output_1_loss: 1.7247 - val_output_accuracy: 0.4636 - val_auxilliary_output_1_accuracy: 0.4625 - lr: 0.0069\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
            "Epoch 48/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.1236 - output_loss: 0.8183 - auxilliary_output_1_loss: 1.0179 - output_accuracy: 0.7082 - auxilliary_output_1_accuracy: 0.6370 - val_loss: 2.4170 - val_output_loss: 1.8993 - val_auxilliary_output_1_loss: 1.7257 - val_output_accuracy: 0.4609 - val_auxilliary_output_1_accuracy: 0.4579 - lr: 0.0069\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.0069253399582448.\n",
            "Epoch 49/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.0615 - output_loss: 0.7664 - auxilliary_output_1_loss: 0.9836 - output_accuracy: 0.7246 - auxilliary_output_1_accuracy: 0.6495 - val_loss: 2.4953 - val_output_loss: 1.9775 - val_auxilliary_output_1_loss: 1.7260 - val_output_accuracy: 0.4633 - val_auxilliary_output_1_accuracy: 0.4651 - lr: 0.0069\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
            "Epoch 50/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 1.0841 - output_loss: 0.7841 - auxilliary_output_1_loss: 1.0001 - output_accuracy: 0.7185 - auxilliary_output_1_accuracy: 0.6460 - val_loss: 2.4108 - val_output_loss: 1.9063 - val_auxilliary_output_1_loss: 1.6820 - val_output_accuracy: 0.4629 - val_auxilliary_output_1_accuracy: 0.4680 - lr: 0.0066\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
            "Epoch 51/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.0096 - output_loss: 0.7226 - auxilliary_output_1_loss: 0.9567 - output_accuracy: 0.7412 - auxilliary_output_1_accuracy: 0.6599 - val_loss: 2.5616 - val_output_loss: 2.0384 - val_auxilliary_output_1_loss: 1.7442 - val_output_accuracy: 0.4553 - val_auxilliary_output_1_accuracy: 0.4550 - lr: 0.0066\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
            "Epoch 52/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.0094 - output_loss: 0.7228 - auxilliary_output_1_loss: 0.9552 - output_accuracy: 0.7441 - auxilliary_output_1_accuracy: 0.6602 - val_loss: 2.5846 - val_output_loss: 2.0651 - val_auxilliary_output_1_loss: 1.7318 - val_output_accuracy: 0.4627 - val_auxilliary_output_1_accuracy: 0.4634 - lr: 0.0066\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
            "Epoch 53/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 1.0673 - output_loss: 0.7702 - auxilliary_output_1_loss: 0.9906 - output_accuracy: 0.7247 - auxilliary_output_1_accuracy: 0.6479 - val_loss: 2.5231 - val_output_loss: 2.0011 - val_auxilliary_output_1_loss: 1.7400 - val_output_accuracy: 0.4645 - val_auxilliary_output_1_accuracy: 0.4642 - lr: 0.0066\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.006648326359915008.\n",
            "Epoch 54/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 1.0107 - output_loss: 0.7230 - auxilliary_output_1_loss: 0.9591 - output_accuracy: 0.7410 - auxilliary_output_1_accuracy: 0.6599 - val_loss: 2.7900 - val_output_loss: 2.2432 - val_auxilliary_output_1_loss: 1.8227 - val_output_accuracy: 0.4504 - val_auxilliary_output_1_accuracy: 0.4528 - lr: 0.0066\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
            "Epoch 55/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.9286 - output_loss: 0.6545 - auxilliary_output_1_loss: 0.9139 - output_accuracy: 0.7662 - auxilliary_output_1_accuracy: 0.6740 - val_loss: 2.8597 - val_output_loss: 2.3005 - val_auxilliary_output_1_loss: 1.8639 - val_output_accuracy: 0.4569 - val_auxilliary_output_1_accuracy: 0.4573 - lr: 0.0064\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
            "Epoch 56/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.9829 - output_loss: 0.7010 - auxilliary_output_1_loss: 0.9396 - output_accuracy: 0.7524 - auxilliary_output_1_accuracy: 0.6647 - val_loss: 2.8449 - val_output_loss: 2.2853 - val_auxilliary_output_1_loss: 1.8651 - val_output_accuracy: 0.4566 - val_auxilliary_output_1_accuracy: 0.4552 - lr: 0.0064\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
            "Epoch 57/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.9185 - output_loss: 0.6457 - auxilliary_output_1_loss: 0.9094 - output_accuracy: 0.7699 - auxilliary_output_1_accuracy: 0.6774 - val_loss: 2.9059 - val_output_loss: 2.3383 - val_auxilliary_output_1_loss: 1.8921 - val_output_accuracy: 0.4442 - val_auxilliary_output_1_accuracy: 0.4475 - lr: 0.0064\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
            "Epoch 58/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.9637 - output_loss: 0.6845 - auxilliary_output_1_loss: 0.9307 - output_accuracy: 0.7576 - auxilliary_output_1_accuracy: 0.6711 - val_loss: 2.7679 - val_output_loss: 2.2273 - val_auxilliary_output_1_loss: 1.8023 - val_output_accuracy: 0.4574 - val_auxilliary_output_1_accuracy: 0.4583 - lr: 0.0064\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.006382393305518408.\n",
            "Epoch 59/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 0.8687 - output_loss: 0.6063 - auxilliary_output_1_loss: 0.8747 - output_accuracy: 0.7842 - auxilliary_output_1_accuracy: 0.6906 - val_loss: 3.0895 - val_output_loss: 2.5256 - val_auxilliary_output_1_loss: 1.8794 - val_output_accuracy: 0.4485 - val_auxilliary_output_1_accuracy: 0.4467 - lr: 0.0064\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
            "Epoch 60/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.8539 - output_loss: 0.5938 - auxilliary_output_1_loss: 0.8671 - output_accuracy: 0.7884 - auxilliary_output_1_accuracy: 0.6909 - val_loss: 3.0495 - val_output_loss: 2.4808 - val_auxilliary_output_1_loss: 1.8956 - val_output_accuracy: 0.4442 - val_auxilliary_output_1_accuracy: 0.4544 - lr: 0.0061\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
            "Epoch 61/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.8161 - output_loss: 0.5615 - auxilliary_output_1_loss: 0.8484 - output_accuracy: 0.8014 - auxilliary_output_1_accuracy: 0.7009 - val_loss: 3.0540 - val_output_loss: 2.4821 - val_auxilliary_output_1_loss: 1.9062 - val_output_accuracy: 0.4564 - val_auxilliary_output_1_accuracy: 0.4577 - lr: 0.0061\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
            "Epoch 62/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.8182 - output_loss: 0.5637 - auxilliary_output_1_loss: 0.8482 - output_accuracy: 0.7994 - auxilliary_output_1_accuracy: 0.6981 - val_loss: 3.3550 - val_output_loss: 2.7459 - val_auxilliary_output_1_loss: 2.0302 - val_output_accuracy: 0.4464 - val_auxilliary_output_1_accuracy: 0.4505 - lr: 0.0061\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
            "Epoch 63/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.7929 - output_loss: 0.5412 - auxilliary_output_1_loss: 0.8390 - output_accuracy: 0.8085 - auxilliary_output_1_accuracy: 0.7037 - val_loss: 3.2245 - val_output_loss: 2.6436 - val_auxilliary_output_1_loss: 1.9360 - val_output_accuracy: 0.4465 - val_auxilliary_output_1_accuracy: 0.4494 - lr: 0.0061\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.006127097573297671.\n",
            "Epoch 64/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.8063 - output_loss: 0.5544 - auxilliary_output_1_loss: 0.8396 - output_accuracy: 0.8052 - auxilliary_output_1_accuracy: 0.7017 - val_loss: 3.2280 - val_output_loss: 2.6282 - val_auxilliary_output_1_loss: 1.9992 - val_output_accuracy: 0.4521 - val_auxilliary_output_1_accuracy: 0.4533 - lr: 0.0061\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
            "Epoch 65/100\n",
            "98/98 [==============================] - 6s 57ms/step - loss: 0.7631 - output_loss: 0.5176 - auxilliary_output_1_loss: 0.8184 - output_accuracy: 0.8163 - auxilliary_output_1_accuracy: 0.7084 - val_loss: 3.1277 - val_output_loss: 2.5492 - val_auxilliary_output_1_loss: 1.9281 - val_output_accuracy: 0.4575 - val_auxilliary_output_1_accuracy: 0.4546 - lr: 0.0059\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
            "Epoch 66/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.7051 - output_loss: 0.4701 - auxilliary_output_1_loss: 0.7833 - output_accuracy: 0.8332 - auxilliary_output_1_accuracy: 0.7217 - val_loss: 3.6481 - val_output_loss: 3.0233 - val_auxilliary_output_1_loss: 2.0828 - val_output_accuracy: 0.4536 - val_auxilliary_output_1_accuracy: 0.4460 - lr: 0.0059\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
            "Epoch 67/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.7024 - output_loss: 0.4671 - auxilliary_output_1_loss: 0.7842 - output_accuracy: 0.8348 - auxilliary_output_1_accuracy: 0.7215 - val_loss: 3.4792 - val_output_loss: 2.8437 - val_auxilliary_output_1_loss: 2.1181 - val_output_accuracy: 0.4458 - val_auxilliary_output_1_accuracy: 0.4386 - lr: 0.0059\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
            "Epoch 68/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.7351 - output_loss: 0.4938 - auxilliary_output_1_loss: 0.8042 - output_accuracy: 0.8266 - auxilliary_output_1_accuracy: 0.7161 - val_loss: 3.5366 - val_output_loss: 2.9152 - val_auxilliary_output_1_loss: 2.0712 - val_output_accuracy: 0.4526 - val_auxilliary_output_1_accuracy: 0.4519 - lr: 0.0059\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.005882013670365765.\n",
            "Epoch 69/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.6817 - output_loss: 0.4507 - auxilliary_output_1_loss: 0.7698 - output_accuracy: 0.8422 - auxilliary_output_1_accuracy: 0.7298 - val_loss: 3.6454 - val_output_loss: 3.0021 - val_auxilliary_output_1_loss: 2.1443 - val_output_accuracy: 0.4461 - val_auxilliary_output_1_accuracy: 0.4440 - lr: 0.0059\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
            "Epoch 70/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.6781 - output_loss: 0.4464 - auxilliary_output_1_loss: 0.7722 - output_accuracy: 0.8455 - auxilliary_output_1_accuracy: 0.7269 - val_loss: 3.5319 - val_output_loss: 2.9050 - val_auxilliary_output_1_loss: 2.0898 - val_output_accuracy: 0.4491 - val_auxilliary_output_1_accuracy: 0.4497 - lr: 0.0056\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
            "Epoch 71/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.6529 - output_loss: 0.4276 - auxilliary_output_1_loss: 0.7508 - output_accuracy: 0.8493 - auxilliary_output_1_accuracy: 0.7358 - val_loss: 3.6268 - val_output_loss: 3.0020 - val_auxilliary_output_1_loss: 2.0827 - val_output_accuracy: 0.4457 - val_auxilliary_output_1_accuracy: 0.4448 - lr: 0.0056\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
            "Epoch 72/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.6614 - output_loss: 0.4327 - auxilliary_output_1_loss: 0.7624 - output_accuracy: 0.8477 - auxilliary_output_1_accuracy: 0.7337 - val_loss: 3.4719 - val_output_loss: 2.8686 - val_auxilliary_output_1_loss: 2.0110 - val_output_accuracy: 0.4394 - val_auxilliary_output_1_accuracy: 0.4497 - lr: 0.0056\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
            "Epoch 73/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.6609 - output_loss: 0.4334 - auxilliary_output_1_loss: 0.7583 - output_accuracy: 0.8494 - auxilliary_output_1_accuracy: 0.7334 - val_loss: 3.6889 - val_output_loss: 3.0506 - val_auxilliary_output_1_loss: 2.1277 - val_output_accuracy: 0.4482 - val_auxilliary_output_1_accuracy: 0.4465 - lr: 0.0056\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.005646733123551133.\n",
            "Epoch 74/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.6222 - output_loss: 0.4023 - auxilliary_output_1_loss: 0.7329 - output_accuracy: 0.8618 - auxilliary_output_1_accuracy: 0.7444 - val_loss: 3.5185 - val_output_loss: 2.9057 - val_auxilliary_output_1_loss: 2.0426 - val_output_accuracy: 0.4478 - val_auxilliary_output_1_accuracy: 0.4540 - lr: 0.0056\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
            "Epoch 75/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.6100 - output_loss: 0.3920 - auxilliary_output_1_loss: 0.7266 - output_accuracy: 0.8639 - auxilliary_output_1_accuracy: 0.7452 - val_loss: 3.9595 - val_output_loss: 3.2968 - val_auxilliary_output_1_loss: 2.2089 - val_output_accuracy: 0.4507 - val_auxilliary_output_1_accuracy: 0.4496 - lr: 0.0054\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
            "Epoch 76/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5921 - output_loss: 0.3778 - auxilliary_output_1_loss: 0.7144 - output_accuracy: 0.8690 - auxilliary_output_1_accuracy: 0.7500 - val_loss: 3.5138 - val_output_loss: 2.8975 - val_auxilliary_output_1_loss: 2.0542 - val_output_accuracy: 0.4493 - val_auxilliary_output_1_accuracy: 0.4486 - lr: 0.0054\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
            "Epoch 77/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.5907 - output_loss: 0.3773 - auxilliary_output_1_loss: 0.7115 - output_accuracy: 0.8687 - auxilliary_output_1_accuracy: 0.7491 - val_loss: 3.8488 - val_output_loss: 3.1954 - val_auxilliary_output_1_loss: 2.1779 - val_output_accuracy: 0.4488 - val_auxilliary_output_1_accuracy: 0.4495 - lr: 0.0054\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
            "Epoch 78/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5786 - output_loss: 0.3676 - auxilliary_output_1_loss: 0.7033 - output_accuracy: 0.8723 - auxilliary_output_1_accuracy: 0.7541 - val_loss: 4.0138 - val_output_loss: 3.3374 - val_auxilliary_output_1_loss: 2.2544 - val_output_accuracy: 0.4478 - val_auxilliary_output_1_accuracy: 0.4437 - lr: 0.0054\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.005420863798609088.\n",
            "Epoch 79/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5653 - output_loss: 0.3557 - auxilliary_output_1_loss: 0.6989 - output_accuracy: 0.8771 - auxilliary_output_1_accuracy: 0.7559 - val_loss: 3.8230 - val_output_loss: 3.1606 - val_auxilliary_output_1_loss: 2.2078 - val_output_accuracy: 0.4525 - val_auxilliary_output_1_accuracy: 0.4460 - lr: 0.0054\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
            "Epoch 80/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.5353 - output_loss: 0.3326 - auxilliary_output_1_loss: 0.6758 - output_accuracy: 0.8859 - auxilliary_output_1_accuracy: 0.7631 - val_loss: 4.2083 - val_output_loss: 3.5480 - val_auxilliary_output_1_loss: 2.2010 - val_output_accuracy: 0.4452 - val_auxilliary_output_1_accuracy: 0.4432 - lr: 0.0052\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
            "Epoch 81/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5228 - output_loss: 0.3220 - auxilliary_output_1_loss: 0.6694 - output_accuracy: 0.8874 - auxilliary_output_1_accuracy: 0.7633 - val_loss: 4.5947 - val_output_loss: 3.8779 - val_auxilliary_output_1_loss: 2.3892 - val_output_accuracy: 0.4482 - val_auxilliary_output_1_accuracy: 0.4419 - lr: 0.0052\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
            "Epoch 82/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.4865 - output_loss: 0.2927 - auxilliary_output_1_loss: 0.6462 - output_accuracy: 0.8981 - auxilliary_output_1_accuracy: 0.7728 - val_loss: 4.3489 - val_output_loss: 3.6590 - val_auxilliary_output_1_loss: 2.2998 - val_output_accuracy: 0.4478 - val_auxilliary_output_1_accuracy: 0.4434 - lr: 0.0052\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
            "Epoch 83/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5180 - output_loss: 0.3198 - auxilliary_output_1_loss: 0.6606 - output_accuracy: 0.8914 - auxilliary_output_1_accuracy: 0.7698 - val_loss: 4.5735 - val_output_loss: 3.8367 - val_auxilliary_output_1_loss: 2.4561 - val_output_accuracy: 0.4471 - val_auxilliary_output_1_accuracy: 0.4423 - lr: 0.0052\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.005204029246664724.\n",
            "Epoch 84/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.4816 - output_loss: 0.2887 - auxilliary_output_1_loss: 0.6432 - output_accuracy: 0.9014 - auxilliary_output_1_accuracy: 0.7755 - val_loss: 4.7497 - val_output_loss: 4.0336 - val_auxilliary_output_1_loss: 2.3869 - val_output_accuracy: 0.4428 - val_auxilliary_output_1_accuracy: 0.4422 - lr: 0.0052\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
            "Epoch 85/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.4781 - output_loss: 0.2880 - auxilliary_output_1_loss: 0.6334 - output_accuracy: 0.9018 - auxilliary_output_1_accuracy: 0.7778 - val_loss: 4.7191 - val_output_loss: 3.9822 - val_auxilliary_output_1_loss: 2.4563 - val_output_accuracy: 0.4442 - val_auxilliary_output_1_accuracy: 0.4400 - lr: 0.0050\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
            "Epoch 86/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.4156 - output_loss: 0.2379 - auxilliary_output_1_loss: 0.5923 - output_accuracy: 0.9195 - auxilliary_output_1_accuracy: 0.7920 - val_loss: 5.0110 - val_output_loss: 4.2521 - val_auxilliary_output_1_loss: 2.5294 - val_output_accuracy: 0.4484 - val_auxilliary_output_1_accuracy: 0.4466 - lr: 0.0050\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
            "Epoch 87/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.4902 - output_loss: 0.2987 - auxilliary_output_1_loss: 0.6384 - output_accuracy: 0.8991 - auxilliary_output_1_accuracy: 0.7775 - val_loss: 4.7787 - val_output_loss: 4.0374 - val_auxilliary_output_1_loss: 2.4709 - val_output_accuracy: 0.4448 - val_auxilliary_output_1_accuracy: 0.4363 - lr: 0.0050\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
            "Epoch 88/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.4048 - output_loss: 0.2287 - auxilliary_output_1_loss: 0.5870 - output_accuracy: 0.9225 - auxilliary_output_1_accuracy: 0.7973 - val_loss: 4.8093 - val_output_loss: 4.0745 - val_auxilliary_output_1_loss: 2.4495 - val_output_accuracy: 0.4468 - val_auxilliary_output_1_accuracy: 0.4459 - lr: 0.0050\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.004995868076798134.\n",
            "Epoch 89/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.4342 - output_loss: 0.2536 - auxilliary_output_1_loss: 0.6018 - output_accuracy: 0.9148 - auxilliary_output_1_accuracy: 0.7910 - val_loss: 4.8710 - val_output_loss: 4.1154 - val_auxilliary_output_1_loss: 2.5188 - val_output_accuracy: 0.4422 - val_auxilliary_output_1_accuracy: 0.4362 - lr: 0.0050\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
            "Epoch 90/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.3870 - output_loss: 0.2140 - auxilliary_output_1_loss: 0.5767 - output_accuracy: 0.9261 - auxilliary_output_1_accuracy: 0.7991 - val_loss: 5.4733 - val_output_loss: 4.6904 - val_auxilliary_output_1_loss: 2.6096 - val_output_accuracy: 0.4396 - val_auxilliary_output_1_accuracy: 0.4382 - lr: 0.0048\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
            "Epoch 91/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.4102 - output_loss: 0.2359 - auxilliary_output_1_loss: 0.5811 - output_accuracy: 0.9217 - auxilliary_output_1_accuracy: 0.7982 - val_loss: 4.7079 - val_output_loss: 3.9849 - val_auxilliary_output_1_loss: 2.4101 - val_output_accuracy: 0.4490 - val_auxilliary_output_1_accuracy: 0.4447 - lr: 0.0048\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
            "Epoch 92/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.5125 - output_loss: 0.3214 - auxilliary_output_1_loss: 0.6371 - output_accuracy: 0.8951 - auxilliary_output_1_accuracy: 0.7785 - val_loss: 4.9086 - val_output_loss: 4.1689 - val_auxilliary_output_1_loss: 2.4656 - val_output_accuracy: 0.4526 - val_auxilliary_output_1_accuracy: 0.4466 - lr: 0.0048\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
            "Epoch 93/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.4262 - output_loss: 0.2506 - auxilliary_output_1_loss: 0.5853 - output_accuracy: 0.9162 - auxilliary_output_1_accuracy: 0.7961 - val_loss: 5.0795 - val_output_loss: 4.3138 - val_auxilliary_output_1_loss: 2.5521 - val_output_accuracy: 0.4404 - val_auxilliary_output_1_accuracy: 0.4401 - lr: 0.0048\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.004796033353726209.\n",
            "Epoch 94/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.4139 - output_loss: 0.2392 - auxilliary_output_1_loss: 0.5823 - output_accuracy: 0.9213 - auxilliary_output_1_accuracy: 0.7982 - val_loss: 4.9817 - val_output_loss: 4.2193 - val_auxilliary_output_1_loss: 2.5416 - val_output_accuracy: 0.4411 - val_auxilliary_output_1_accuracy: 0.4383 - lr: 0.0048\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
            "Epoch 95/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.3894 - output_loss: 0.2204 - auxilliary_output_1_loss: 0.5635 - output_accuracy: 0.9251 - auxilliary_output_1_accuracy: 0.8057 - val_loss: 5.3120 - val_output_loss: 4.5052 - val_auxilliary_output_1_loss: 2.6894 - val_output_accuracy: 0.4433 - val_auxilliary_output_1_accuracy: 0.4392 - lr: 0.0046\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
            "Epoch 96/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.3604 - output_loss: 0.1982 - auxilliary_output_1_loss: 0.5407 - output_accuracy: 0.9335 - auxilliary_output_1_accuracy: 0.8128 - val_loss: 5.3175 - val_output_loss: 4.5380 - val_auxilliary_output_1_loss: 2.5981 - val_output_accuracy: 0.4471 - val_auxilliary_output_1_accuracy: 0.4408 - lr: 0.0046\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
            "Epoch 97/100\n",
            "98/98 [==============================] - 6s 59ms/step - loss: 0.3843 - output_loss: 0.2169 - auxilliary_output_1_loss: 0.5580 - output_accuracy: 0.9283 - auxilliary_output_1_accuracy: 0.8042 - val_loss: 5.0157 - val_output_loss: 4.2568 - val_auxilliary_output_1_loss: 2.5295 - val_output_accuracy: 0.4475 - val_auxilliary_output_1_accuracy: 0.4444 - lr: 0.0046\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
            "Epoch 98/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.4149 - output_loss: 0.2429 - auxilliary_output_1_loss: 0.5735 - output_accuracy: 0.9194 - auxilliary_output_1_accuracy: 0.8021 - val_loss: 4.9155 - val_output_loss: 4.1471 - val_auxilliary_output_1_loss: 2.5613 - val_output_accuracy: 0.4383 - val_auxilliary_output_1_accuracy: 0.4369 - lr: 0.0046\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 0.004604192019577161.\n",
            "Epoch 99/100\n",
            "98/98 [==============================] - 6s 58ms/step - loss: 0.3725 - output_loss: 0.2104 - auxilliary_output_1_loss: 0.5405 - output_accuracy: 0.9310 - auxilliary_output_1_accuracy: 0.8122 - val_loss: 5.6989 - val_output_loss: 4.8719 - val_auxilliary_output_1_loss: 2.7567 - val_output_accuracy: 0.4380 - val_auxilliary_output_1_accuracy: 0.4380 - lr: 0.0046\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 0.004420024338794074.\n",
            "Epoch 100/100\n",
            "98/98 [==============================] - 6s 60ms/step - loss: 0.3391 - output_loss: 0.1828 - auxilliary_output_1_loss: 0.5213 - output_accuracy: 0.9393 - auxilliary_output_1_accuracy: 0.8213 - val_loss: 5.3130 - val_output_loss: 4.5338 - val_auxilliary_output_1_loss: 2.5974 - val_output_accuracy: 0.4395 - val_auxilliary_output_1_accuracy: 0.4399 - lr: 0.0044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvamento do modelo treinado"
      ],
      "metadata": {
        "id": "f_UyXAlu1S2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_saved_model')"
      ],
      "metadata": {
        "id": "2By38yOvhWc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerar predições do modelo"
      ],
      "metadata": {
        "id": "qGnEfGdA1W7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera previsões\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Separa as previsões principais e auxiliares\n",
        "main_predictions, aux1_predictions = predictions\n",
        "\n",
        "# Verifica a classe prevista e a classe verdadeira para o primeiro exemplo do conjunto de teste\n",
        "predicted_classes = np.argmax(main_predictions, axis=1)\n",
        "true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"Predicted first example class: {predicted_classes[0]}\")\n",
        "print(f\"True first example class: {true_classes[0]}\")"
      ],
      "metadata": {
        "id": "sphXqH21er8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64365a7b-6ab7-4958-e6cc-89c2906c2d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 6ms/step\n",
            "Predicted first example class: 8\n",
            "True first example class: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizar predições erradas"
      ],
      "metadata": {
        "id": "fNSTCaTX13y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "1kG32bm8_XfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para visualizar previsões incorretas\n",
        "def plot_misclassified_images(images, true_labels, predicted_labels, class_names):\n",
        "    misclassified = true_labels != predicted_labels\n",
        "    misclassified_images = images[misclassified]\n",
        "    true_labels = true_labels[misclassified]\n",
        "    predicted_labels = predicted_labels[misclassified]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(min(9, len(misclassified_images))):  # plota até 9 imagens incorretas ou menos se houver menos de 9\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(misclassified_images[i])\n",
        "        true_class_name = class_names[true_labels[i]]\n",
        "        predicted_class_name = class_names[predicted_labels[i]]\n",
        "        plt.title(f\"True: {true_class_name}, Pred: {predicted_class_name}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Exemplo de uso\n",
        "# true_classes e predicted_classes são arrays com os índices das classes verdadeiras e previstas, respectivamente\n",
        "# X_test são as imagens de teste\n",
        "plot_misclassified_images(X_test, true_classes, predicted_classes, class_names)"
      ],
      "metadata": {
        "id": "6wujI38beu0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "outputId": "a99620bd-df48-4fc2-80d1-f00e038fc0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predição de outras imagens"
      ],
      "metadata": {
        "id": "LQI4HyEn17m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de URLs de imagens de teste\n",
        "image_urls = [\n",
        "    'https://marvel-b1-cdn.bc0a.com/f00000000295579/www.tecequipment.com/app/uploads/2020/10/Volvo-VNR-Day-cab.jpg',\n",
        "    'https://www.alleycat.org/wp-content/uploads/2019/03/FELV-cat.jpg'\n",
        "]"
      ],
      "metadata": {
        "id": "McCAqX3O_642"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(url):\n",
        "    try:\n",
        "        # Baixa a imagem da URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Verifica se a requisição foi bem-sucedida\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Redimensiona a imagem para 32x32 pixels\n",
        "        img = img.resize((32, 32))\n",
        "\n",
        "        # Converte a imagem para um array e normaliza os valores\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = img_array / 255.0  # Normaliza a imagem\n",
        "\n",
        "        # Expande as dimensões para se ajustar ao formato esperado pelo modelo\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        return img_array\n",
        "    except (requests.HTTPError, UnidentifiedImageError) as e:\n",
        "        print(f\"Error loading image from {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Processa e faz predições nas imagens\n",
        "for url in image_urls:\n",
        "    img_array = load_and_preprocess_image(url)\n",
        "    if img_array is not None:\n",
        "        predictions = model.predict(img_array)  # Pode retornar uma lista de arrays se houver múltiplas saídas\n",
        "        main_prediction = predictions[0]  # Supondo que a primeira saída é a principal\n",
        "        predicted_class = np.argmax(main_prediction, axis=1)\n",
        "        print(f\"Predicted class for {url}: {class_names[predicted_class[0]]}\")\n",
        "    else:\n",
        "        print(f\"Skipping image from {url} due to loading error.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJV2ZEQHDi3U",
        "outputId": "d7e6de83-c39a-47d2-dc2b-e62e9bcf018a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 836ms/step\n",
            "Predicted class for https://marvel-b1-cdn.bc0a.com/f00000000295579/www.tecequipment.com/app/uploads/2020/10/Volvo-VNR-Day-cab.jpg: truck\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Predicted class for https://www.alleycat.org/wp-content/uploads/2019/03/FELV-cat.jpg: bird\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}